{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae37d80",
   "metadata": {
    "id": "cae37d80",
    "papermill": {
     "duration": 0.084616,
     "end_time": "2021-10-26T11:23:10.119772",
     "exception": false,
     "start_time": "2021-10-26T11:23:10.035156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install & Import Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9300d9e-1a4b-4421-a9b6-2e62b55bad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (25.1.1)\n",
      "Requirement already satisfied: matplotlib in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
      "  Downloading https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
      "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m2.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: yt-dlp\n",
      "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yt-dlp: filename=yt_dlp-2025.5.22-py3-none-any.whl size=3005023 sha256=065f46a7495fbc417eaafcc5d2507cb19c3f4ed38ea3a138a6a9315cb282268a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n12nsiv1/wheels/4c/91/d1/c5369304e2f7afb660bb6eee093af5a7d3c0ea05a3c1e8c797\n",
      "Successfully built yt-dlp\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.5.22\n",
      "Requirement already satisfied: pandas in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install matplotlib\n",
    "#!pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994f5622",
   "metadata": {
    "id": "994f5622",
    "papermill": {
     "duration": 0.103147,
     "end_time": "2021-10-26T11:23:10.309708",
     "exception": false,
     "start_time": "2021-10-26T11:23:10.206561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# https://pypi.org/project/yt-dlp/\n",
    "import json\n",
    "import yt_dlp\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb8b77-bff7-4131-8086-0d4f3ab528c7",
   "metadata": {},
   "source": [
    "## Import Playlist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90ada8e-3451-42b6-af85-71188d9c0eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spotipy\n",
      "  Downloading spotipy-2.25.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting redis>=3.5.3 (from spotipy)\n",
      "  Downloading redis-6.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.25.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from spotipy) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from spotipy) (1.26.19)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from redis>=3.5.3->spotipy) (5.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (2025.4.26)\n",
      "Downloading spotipy-2.25.1-py3-none-any.whl (31 kB)\n",
      "Downloading redis-6.1.0-py3-none-any.whl (273 kB)\n",
      "Installing collected packages: redis, spotipy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [spotipy]\n",
      "\u001b[1A\u001b[2KSuccessfully installed redis-6.1.0 spotipy-2.25.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193eeed5-41d6-4c14-a0c1-4fc064e3a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download Spotify Playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f260917-e177-421e-b809-9a43523e2564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SpotifyOauthError",
     "evalue": "error: invalid_client, error_description: Invalid client",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\oauth2.py:560\u001b[39m, in \u001b[36mSpotifyOAuth.refresh_access_token\u001b[39m\u001b[34m(self, refresh_token)\u001b[39m\n\u001b[32m    553\u001b[39m response = \u001b[38;5;28mself\u001b[39m._session.post(\n\u001b[32m    554\u001b[39m     \u001b[38;5;28mself\u001b[39m.OAUTH_TOKEN_URL,\n\u001b[32m    555\u001b[39m     data=payload,\n\u001b[32m   (...)\u001b[39m\u001b[32m    558\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.requests_timeout,\n\u001b[32m    559\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m token_info = response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 400 Client Error: Bad Request for url: https://accounts.spotify.com/api/token",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mSpotifyOauthError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#Emma's songs\u001b[39;00m\n\u001b[32m     15\u001b[39m playlist_id = \u001b[33m'\u001b[39m\u001b[33m1eZmS24ui4yIpg0SKOs7oV\u001b[39m\u001b[33m'\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m results = \u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplaylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplaylist_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33memmas_playlist.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     19\u001b[39m     json.dump(results, f, indent=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\client.py:668\u001b[39m, in \u001b[36mSpotify.playlist\u001b[39m\u001b[34m(self, playlist_id, fields, market, additional_types)\u001b[39m\n\u001b[32m    657\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Gets playlist by id.\u001b[39;00m\n\u001b[32m    658\u001b[39m \n\u001b[32m    659\u001b[39m \u001b[33;03m    Parameters:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    665\u001b[39m \u001b[33;03m                             valid types are: track and episode\u001b[39;00m\n\u001b[32m    666\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    667\u001b[39m plid = \u001b[38;5;28mself\u001b[39m._get_id(\u001b[33m\"\u001b[39m\u001b[33mplaylist\u001b[39m\u001b[33m\"\u001b[39m, playlist_id)\n\u001b[32m--> \u001b[39m\u001b[32m668\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplaylists/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mplid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmarket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_types\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43madditional_types\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\client.py:324\u001b[39m, in \u001b[36mSpotify._get\u001b[39m\u001b[34m(self, url, args, payload, **kwargs)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[32m    322\u001b[39m     kwargs.update(args)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\client.py:250\u001b[39m, in \u001b[36mSpotify._internal_call\u001b[39m\u001b[34m(self, method, url, payload, params)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m url.startswith(\u001b[33m\"\u001b[39m\u001b[33mhttp\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    249\u001b[39m     url = \u001b[38;5;28mself\u001b[39m.prefix + url\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m headers = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auth_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcontent_type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    253\u001b[39m     headers[\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m] = args[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent_type\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\client.py:241\u001b[39m, in \u001b[36mSpotify._auth_headers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {}\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     token = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauth_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_access_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mas_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    243\u001b[39m     token = \u001b[38;5;28mself\u001b[39m.auth_manager.get_access_token()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\oauth2.py:501\u001b[39m, in \u001b[36mSpotifyOAuth.get_access_token\u001b[39m\u001b[34m(self, code, as_dict, check_cache)\u001b[39m\n\u001b[32m    492\u001b[39m     warnings.warn(\n\u001b[32m    493\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre using \u001b[39m\u001b[33m'\u001b[39m\u001b[33mas_dict = True\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    494\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mget_access_token will return the token string directly in future \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    498\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    499\u001b[39m     )\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_cache:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     token_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate_token\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_cached_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m token_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    503\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_token_expired(token_info):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\oauth2.py:347\u001b[39m, in \u001b[36mSpotifyOAuth.validate_token\u001b[39m\u001b[34m(self, token_info)\u001b[39m\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_token_expired(token_info):\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     token_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrefresh_access_token\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken_info\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrefresh_token\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m token_info\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\oauth2.py:568\u001b[39m, in \u001b[36mSpotifyOAuth.refresh_access_token\u001b[39m\u001b[34m(self, refresh_token)\u001b[39m\n\u001b[32m    566\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m token_info\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.HTTPError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[32m--> \u001b[39m\u001b[32m568\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_oauth_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\spotipy\\oauth2.py:117\u001b[39m, in \u001b[36mSpotifyAuthBase._handle_oauth_error\u001b[39m\u001b[34m(self, http_error)\u001b[39m\n\u001b[32m    114\u001b[39m     error = response.text \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    115\u001b[39m     error_description = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m SpotifyOauthError(\n\u001b[32m    118\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33merror: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, error_description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_description\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m    119\u001b[39m     error=error,\n\u001b[32m    120\u001b[39m     error_description=error_description\n\u001b[32m    121\u001b[39m )\n",
      "\u001b[31mSpotifyOauthError\u001b[39m: error: invalid_client, error_description: Invalid client"
     ]
    }
   ],
   "source": [
    "#https://developer.spotify.com/dashboard/7d18709cd0cd4c3594689384206d4ac6\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import json\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='###',\n",
    "    client_secret='###',\n",
    "    redirect_uri='http://127.0.0.1:8889/callback',\n",
    "    scope=\"playlist-read-private\"\n",
    "))\n",
    "\n",
    "#Emma's songs\n",
    "playlist_id = '1eZmS24ui4yIpg0SKOs7oV' \n",
    "results = sp.playlist(playlist_id)\n",
    "\n",
    "with open(\"emmas_playlist.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f0d06-b815-4cb0-85f5-ffee9683bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data necessary to add it to the other playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e120f5b4-ceff-436b-b490-84d111e61000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load your downloaded JSON file\n",
    "with open(\"emmas_playlist.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract general playlist info\n",
    "playlist_info = {\n",
    "    \"name\": data[\"name\"],\n",
    "    \"pid\": 42,  # You can change or generate this if needed\n",
    "    \"num_tracks\": len(data[\"tracks\"][\"items\"]),\n",
    "    \"num_albums\": len(set(item[\"track\"][\"album\"][\"name\"] for item in data[\"tracks\"][\"items\"])),\n",
    "    \"num_artists\": len(set(artist[\"name\"]\n",
    "                           for item in data[\"tracks\"][\"items\"]\n",
    "                           for artist in item[\"track\"][\"artists\"])),\n",
    "    \"num_followers\": data.get(\"followers\", {}).get(\"total\", 0),\n",
    "    \"collaborative\": str(data.get(\"collaborative\", False)).lower(),\n",
    "    \"0\": []\n",
    "}\n",
    "\n",
    "# Add each track\n",
    "for idx, item in enumerate(data[\"tracks\"][\"items\"]):\n",
    "    track = item[\"track\"]\n",
    "    playlist_info[\"0\"].append({\n",
    "        \"track_name\": track[\"name\"],\n",
    "        \"pos\": idx,\n",
    "        \"album_name\": track[\"album\"][\"name\"],\n",
    "        \"artist_name\": track[\"artists\"][0][\"name\"],  # First artist only\n",
    "        \"duration_ms\": track[\"duration_ms\"]\n",
    "    })\n",
    "\n",
    "# Save the cleaned playlist info\n",
    "with open(\"cleaned_playlist.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(playlist_info, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7e202-71d2-4d7a-bba6-bcc1ea5f7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download YouTube Playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "862880ff-3c15-475c-be0f-e90d79173c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=LL\n",
      "[youtube:tab] LL: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] The provided YouTube account cookies are no longer valid. They have likely been rotated in the browser as a security measure. For tips on how to effectively export YouTube cookies, refer to  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies .\n",
      "WARNING: [youtube:tab] YouTube said: The playlist does not exist.\n",
      "ERROR: [youtube:tab] LL: YouTube said: The playlist does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to fetch playlist: ERROR: [youtube:tab] LL: YouTube said: The playlist does not exist.\n",
      "⚠️ Skipping video at index 103: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 118: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 166: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 199: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 318: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 435: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 437: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 486: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 567: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 610: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 637: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 685: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 692: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 730: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 736: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "\n",
      "✅ Saved liked_videos.json with 729 tracks.\n"
     ]
    }
   ],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "import json\n",
    "\n",
    "ydl_opts = {\n",
    "    'cookiefile': 'cookies.txt',\n",
    "    'quiet': False,\n",
    "    'skip_download': True,\n",
    "    'extract_flat': False,\n",
    "}\n",
    "\n",
    "with YoutubeDL(ydl_opts) as ydl:\n",
    "    url = \"https://www.youtube.com/playlist?list=LL\"\n",
    "    try:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch playlist: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    playlist_data = {\n",
    "        \"name\": info.get(\"title\", \"Liked Videos\"),\n",
    "        \"pid\": info.get(\"id\", \"LL\"),\n",
    "        \"num_tracks\": 0,\n",
    "        \"num_albums\": 0,\n",
    "        \"num_artists\": 0,\n",
    "        \"num_followers\": 0,\n",
    "        \"collaborative\": \"false\",\n",
    "        \"0\": []\n",
    "    }\n",
    "\n",
    "    seen_artists = set()\n",
    "    successful_tracks = 0\n",
    "\n",
    "    for i, entry in enumerate(info.get(\"entries\", [])):\n",
    "        try:\n",
    "            if not entry:\n",
    "                continue\n",
    "\n",
    "            track_name = entry.get(\"title\", \"Unknown Title\")\n",
    "            artist_name = entry.get(\"uploader\", \"Unknown Artist\")\n",
    "            duration = entry.get(\"duration\", 0)  # in seconds\n",
    "\n",
    "            seen_artists.add(artist_name)\n",
    "\n",
    "            track_info = {\n",
    "                \"track_name\": track_name,\n",
    "                \"pos\": successful_tracks,\n",
    "                \"album_name\": \"YouTube\",\n",
    "                \"artist_name\": artist_name,\n",
    "                \"duration_ms\": duration * 1000\n",
    "            }\n",
    "\n",
    "            playlist_data[\"0\"].append(track_info)\n",
    "            successful_tracks += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping video at index {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Finalize counts\n",
    "    playlist_data[\"num_tracks\"] = successful_tracks\n",
    "    playlist_data[\"num_artists\"] = len(seen_artists)\n",
    "\n",
    "    # Save to JSON\n",
    "    try:\n",
    "        with open(\"liked_videos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(playlist_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\n✅ Saved liked_videos.json with {successful_tracks} tracks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to save JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16321d3-3bcc-49d9-a07b-8fd7503e3d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ingest the Playlist and Begin Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wHzfuC9r5CCD",
   "metadata": {
    "id": "wHzfuC9r5CCD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>pos</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_pid</th>\n",
       "      <th>playlist_num_tracks</th>\n",
       "      <th>playlist_num_albums</th>\n",
       "      <th>playlist_num_artists</th>\n",
       "      <th>playlist_num_followers</th>\n",
       "      <th>playlist_collaborative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How I Feel</td>\n",
       "      <td>0</td>\n",
       "      <td>How I Feel</td>\n",
       "      <td>Flo Rida</td>\n",
       "      <td>169557</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lo Que No Sabes Tú</td>\n",
       "      <td>1</td>\n",
       "      <td>Mi Niña Bonita - Reloaded</td>\n",
       "      <td>Chino &amp; Nacho</td>\n",
       "      <td>232120</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chucuchá</td>\n",
       "      <td>2</td>\n",
       "      <td>El Sonido</td>\n",
       "      <td>Ilegales</td>\n",
       "      <td>206959</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mueva la colita</td>\n",
       "      <td>3</td>\n",
       "      <td>Top Caribe</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>242373</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Be My Baby</td>\n",
       "      <td>4</td>\n",
       "      <td>Lloviendo Estrellas</td>\n",
       "      <td>Leslie Grace</td>\n",
       "      <td>218253</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           track_name  pos                 album_name      artist_name  \\\n",
       "0          How I Feel    0                 How I Feel         Flo Rida   \n",
       "1  Lo Que No Sabes Tú    1  Mi Niña Bonita - Reloaded    Chino & Nacho   \n",
       "2            Chucuchá    2                  El Sonido         Ilegales   \n",
       "3     Mueva la colita    3                 Top Caribe  Various Artists   \n",
       "4          Be My Baby    4        Lloviendo Estrellas     Leslie Grace   \n",
       "\n",
       "   duration_ms playlist_name playlist_pid  playlist_num_tracks  \\\n",
       "0       169557          2014            8                   21   \n",
       "1       232120          2014            8                   21   \n",
       "2       206959          2014            8                   21   \n",
       "3       242373          2014            8                   21   \n",
       "4       218253          2014            8                   21   \n",
       "\n",
       "   playlist_num_albums  playlist_num_artists  playlist_num_followers  \\\n",
       "0                   21                    19                       1   \n",
       "1                   21                    19                       1   \n",
       "2                   21                    19                       1   \n",
       "3                   21                    19                       1   \n",
       "4                   21                    19                       1   \n",
       "\n",
       "  playlist_collaborative  \n",
       "0                  false  \n",
       "1                  false  \n",
       "2                  false  \n",
       "3                  false  \n",
       "4                  false  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the playlist into df\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Remove characters not allowed in filenames (Windows, macOS, Linux)\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', '', filename)\n",
    "\n",
    "# Load JSON from file\n",
    "working_dir = 'C:/Users/carja/Documents/Capstone/data/'\n",
    "#working_dir = '/mnt/c/Users/carja/Documents/Capstone/data/'\n",
    "with open(working_dir + 'playlist_data3.json', encoding='utf-8') as f:\n",
    "    playlists  = json.load(f)\n",
    "\n",
    "# Flattened track list\n",
    "track_rows = []\n",
    "\n",
    "for playlist in playlists:\n",
    "    # Extract playlist metadata (everything except the track list)\n",
    "    playlist_metadata = {k: v for k, v in playlist.items() if k != '0'}\n",
    "    \n",
    "    # Extract the track list (the key \"0\" holds the tracks)\n",
    "    tracks = playlist.get(\"0\", [])\n",
    "    \n",
    "    for track in tracks:\n",
    "        # Combine track data with playlist metadata\n",
    "        combined = {**track, **playlist_metadata}\n",
    "        track_rows.append(combined)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(track_rows)\n",
    "\n",
    "# Optional: Rename playlist fields to make it clear\n",
    "playlist_fields = ['name', 'pid', 'num_tracks', 'num_albums', 'num_artists', 'num_followers', 'collaborative']\n",
    "df.rename(columns={field: f'playlist_{field}' for field in playlist_fields}, inplace=True)\n",
    "\n",
    "# first remove duplicate tracks to avoid downloading twice\n",
    "df = df.drop_duplicates(subset=['artist_name', 'track_name'])\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea12ee94-3bfd-4009-97b1-e831f0a9d38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>pos</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_pid</th>\n",
       "      <th>playlist_num_tracks</th>\n",
       "      <th>playlist_num_albums</th>\n",
       "      <th>playlist_num_artists</th>\n",
       "      <th>playlist_num_followers</th>\n",
       "      <th>playlist_collaborative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>The Green Man - Ragtime</td>\n",
       "      <td>717</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>asx</td>\n",
       "      <td>376000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>KIOKO et NISSUI YAKI ONIGIRI 6</td>\n",
       "      <td>720</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>Kioko épicerie japonaise</td>\n",
       "      <td>166000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>\"Weird Al\" Yankovic - Fat (Official Video)</td>\n",
       "      <td>723</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>alyankovic</td>\n",
       "      <td>297000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>Equestria Girls - Rainbow Rocks - 'My Past is ...</td>\n",
       "      <td>726</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>My Little Pony - Official Channel</td>\n",
       "      <td>182000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>Heartcatch Pretty Cure 3rd OP</td>\n",
       "      <td>727</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>mintjn666</td>\n",
       "      <td>86000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             track_name  pos album_name  \\\n",
       "1538                            The Green Man - Ragtime  717    YouTube   \n",
       "1539                     KIOKO et NISSUI YAKI ONIGIRI 6  720    YouTube   \n",
       "1540         \"Weird Al\" Yankovic - Fat (Official Video)  723    YouTube   \n",
       "1541  Equestria Girls - Rainbow Rocks - 'My Past is ...  726    YouTube   \n",
       "1542                      Heartcatch Pretty Cure 3rd OP  727    YouTube   \n",
       "\n",
       "                            artist_name  duration_ms playlist_name  \\\n",
       "1538                                asx       376000  Liked videos   \n",
       "1539           Kioko épicerie japonaise       166000  Liked videos   \n",
       "1540                         alyankovic       297000  Liked videos   \n",
       "1541  My Little Pony - Official Channel       182000  Liked videos   \n",
       "1542                          mintjn666        86000  Liked videos   \n",
       "\n",
       "     playlist_pid  playlist_num_tracks  playlist_num_albums  \\\n",
       "1538           LL                  729                    0   \n",
       "1539           LL                  729                    0   \n",
       "1540           LL                  729                    0   \n",
       "1541           LL                  729                    0   \n",
       "1542           LL                  729                    0   \n",
       "\n",
       "      playlist_num_artists  playlist_num_followers playlist_collaborative  \n",
       "1538                   530                       0                  false  \n",
       "1539                   530                       0                  false  \n",
       "1540                   530                       0                  false  \n",
       "1541                   530                       0                  false  \n",
       "1542                   530                       0                  false  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d584d99-ba09-492c-a8be-d755eaba5a50",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8784e-0170-40c2-b7d3-e5b486452e38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "fbea0d6e",
    "outputId": "731f7641-13dd-4484-a8ea-106558254bc5",
    "papermill": {
     "duration": 0.13467,
     "end_time": "2021-10-26T11:23:10.700195",
     "exception": false,
     "start_time": "2021-10-26T11:23:10.565525",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "source": [
    "### How many unique albums/tracks/artists are there on playlists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6891116-3556-4394-bcdb-9841fe8a99f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique albums: 1146\n",
      "Unique tracks: 1480\n",
      "Unique artists: 929\n"
     ]
    }
   ],
   "source": [
    "# Unique albums\n",
    "count = df[['artist_name', 'album_name']].drop_duplicates().shape[0]\n",
    "print(\"Unique albums:\", count)\n",
    "\n",
    "# Unique tracks\n",
    "count = df[['artist_name', 'track_name']].drop_duplicates().shape[0]\n",
    "print(\"Unique tracks:\", count)\n",
    "\n",
    "# Unique artists\n",
    "count = df[['artist_name']].drop_duplicates().shape[0]\n",
    "print(\"Unique artists:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572524cf-9d88-4d32-9493-6eb805bc9911",
   "metadata": {},
   "source": [
    "### How many times is the next track from the same album/artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0666c3-b969-441a-8e9e-81d4a5aab017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consecutive tracks by the same album: 786\n",
      "Consecutive tracks by the same artist: 204\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_sequential_matches(df, group_by='playlist_pid', order_by='pos', compare_field='artist_name'):\n",
    "    \"\"\"\n",
    "    Count the number of times two consecutive tracks within the same playlist\n",
    "    share the same value for a specified metadata field (e.g., artist, album).\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame with at least the playlist ID, track position, and metadata field.\n",
    "    - group_by: column to group by (usually playlist ID).\n",
    "    - order_by: column indicating order of tracks within group (usually track position).\n",
    "    - compare_field: metadata field to compare between consecutive tracks.\n",
    "\n",
    "    Returns:\n",
    "    - count: int, number of sequential matches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure correct ordering\n",
    "    df_sorted = df.sort_values(by=[group_by, order_by]).copy()\n",
    "\n",
    "    # Shift the compare_field to get previous track's value\n",
    "    df_sorted['prev_value'] = df_sorted.groupby(group_by)[compare_field].shift()\n",
    "\n",
    "    # Check for equality between current and previous track's metadata\n",
    "    df_sorted['sequential_match'] = df_sorted[compare_field] == df_sorted['prev_value']\n",
    "\n",
    "    # Count number of True values\n",
    "    count = df_sorted['sequential_match'].sum()\n",
    "\n",
    "    return count\n",
    "\n",
    "count = count_sequential_matches(df, compare_field='album_name')\n",
    "print(\"Consecutive tracks by the same album:\", count)\n",
    "\n",
    "count = count_sequential_matches(df)\n",
    "print(\"Consecutive tracks by the same artist:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09555f7-67bf-4b9a-99d5-04942ee86fac",
   "metadata": {},
   "source": [
    "### Who are the top artists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ef272f-c6a6-4f68-aec9-e8f2f3265016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 artists: artist_name\n",
      "Eve                32\n",
      "A.R. Rahman        26\n",
      "RHINO              19\n",
      "Lata Mangeshkar    19\n",
      "natori             16\n",
      "TopPop             15\n",
      "Ed Sheeran         14\n",
      "Arijit Singh       14\n",
      "Ado                13\n",
      "Pritam             13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_top_artists(df, artist_col='artist_name', top_n=10):\n",
    "    \"\"\"\n",
    "    Returns the top N artists based on track frequency in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing tracks.\n",
    "    - artist_col: column name containing artist names.\n",
    "    - top_n: number of top artists to return.\n",
    "\n",
    "    Returns:\n",
    "    - pandas Series with artist names as index and counts as values.\n",
    "    \"\"\"\n",
    "    return df[artist_col].value_counts().head(top_n)\n",
    "\n",
    "top10Artists = get_top_artists(df)\n",
    "print(\"Top 10 artists:\", top10Artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e65a81-2926-487c-bf46-84cd10a65e63",
   "metadata": {},
   "source": [
    "### How many different albums are there for each artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb73684-0dc2-4027-b5a3-319bf2aabfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 artists by number of albums.\n",
      "\n",
      "          artist_name  unique_album_count\n",
      "234              Eve                  17\n",
      "10       A.R. Rahman                  14\n",
      "419  Lata Mangeshkar                  11\n",
      "25               Ado                  11\n",
      "896           natori                   9\n",
      "420             Lavt                   8\n",
      "55      Arijit Singh                   7\n",
      "324     Jack Johnson                   7\n",
      "735      The Beatles                   7\n",
      "489    Mohammed Rafi                   7\n"
     ]
    }
   ],
   "source": [
    "album_counts = (\n",
    "    df.groupby('artist_name')['album_name']\n",
    "      .nunique()       # count unique albums per artist\n",
    "      .reset_index()   # convert Series back to DataFrame\n",
    "      .rename(columns={'album_name': 'unique_album_count'})\n",
    "      .sort_values(by='unique_album_count', ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "print(\"Top 10 artists by number of albums.\\n\\n\", album_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e120f3f-9a63-479d-a9d9-5c46b92da1f4",
   "metadata": {},
   "source": [
    "# Audio Download\n",
    "### https://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#usage-and-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cc5e3aa-d501-4236-ada4-d8fd223a12e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yt-dlp in c:\\users\\carja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2025.5.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'yt-dlp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a0560b9-4e4f-49ce-9dfe-8589ecb2c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] -6VYh3fVXlc: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 9zgtT0eCHd4: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] jGflUbPQfW8: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] v4KCuphhFYw: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] CMj-RA8xVIY: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] bzSTpdcs-EI: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] euCqAq6BRa4: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 5fcTCMWx2-s: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] JFF_Mss_uLc: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] JFF_Mss_uLc: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] SfCsb4Ck75w: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] HbHpNpIGI7Q: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] KEI4qSrkPAs: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] -Iq9usG3mBM: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] -Iq9usG3mBM: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 0Z_YqhYHhpg: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] JhoK7chbpZ0: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] JhoK7chbpZ0: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] nqxVMLVe62U: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] DfKe8K1A3JI: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] _vSwyFLdrFs: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] AdDnqSFYXFs: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] RhxF9Qg5mOU: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] xvqeSJlgaNk: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] -XYBj0J99i8: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] QlJ7jPDJhyU: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] QlJ7jPDJhyU: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] DfwsXn5n8HU: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] zg21Rkew874: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] xnKOVPXhlnE: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] qZTwjljm5qc: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] i6iBAuwBODA: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] pbG5iSOe4Y0: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] UFJ0cQ_2-JQ: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] RZUq6N7Gx1c: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0.  Downloaded 1480. Total 1543                                  \n"
     ]
    }
   ],
   "source": [
    "# Loop over your DataFrame rows and Download the music\n",
    "import os\n",
    "\n",
    "def download_track(search_query, output_template):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'quiet': True,\n",
    "        'noplaylist': True,\n",
    "        'outtmpl': output_template,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([f\"ytsearch1:{search_query}\"])\n",
    "        #print(f\"Downloaded: {search_query}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download '{search_query}': {e}\")   \n",
    "\n",
    "# Make sure downloads folder exists\n",
    "output_dir = working_dir + 'downloads'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "download_count = 0\n",
    "skip_count, download_count = 0, 0\n",
    "for ii, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    safe_name = sanitize_filename(f\"{artist} - {track}\")\n",
    "    output_template = output_dir + '/' + safe_name # os.path.join(output_dir, safe_name)\n",
    "\n",
    "     # ✅ Skip if file already exists\n",
    "    if os.path.exists(output_template):\n",
    "        skip_count += 1\n",
    "        print(f\"Skipping (already exists): {output_template}\")\n",
    "        continue\n",
    "    \n",
    "    download_track(safe_name, output_template)\n",
    "    download_count += 1\n",
    "\n",
    "print(f\"Skipped {skip_count}.  Downloaded {download_count}. Total {ii + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af89d5cc-bda3-4831-a2f6-fe77bf567c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ii' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mset_channels(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mset_frame_rate(\u001b[38;5;241m44100\u001b[39m)\n\u001b[1;32m     28\u001b[0m     audio\u001b[38;5;241m.\u001b[39mexport(wav_file, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskip_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Converted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwav_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Total \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mii\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ii' is not defined"
     ]
    }
   ],
   "source": [
    "## Convert mp3 to wavfrom\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Make sure downloads folder exists\n",
    "wav_dir = working_dir + 'wavs'\n",
    "os.makedirs(wav_dir, exist_ok=True)\n",
    "mp3_dir = working_dir + 'downloads'\n",
    "\n",
    "# Loop over your DataFrame rows\n",
    "skip_count, wav_count = 0, 0\n",
    "for idx, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    mp3_name = sanitize_filename(f\"{artist} - {track}.mp3\")\n",
    "    mp3_file = mp3_dir + '/' + mp3_name #os.path.join(output_dir, mp3_name)\n",
    "    wav_name = sanitize_filename(f\"{artist} - {track}.wav\")\n",
    "    wav_file = wav_dir + '/' + wav_name #os.path.join(wav_dir, wav_name)\n",
    "\n",
    "     # ✅ Skip if file doesn't exists\n",
    "    if not os.path.exists(mp3_file) or os.path.exists(wav_file):\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    wav_count += 1\n",
    "    \n",
    "    audio = AudioSegment.from_mp3(mp3_file)\n",
    "    audio = audio.set_channels(1).set_frame_rate(44100)\n",
    "    audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "print(f\"Skipped {skip_count}. Converted {wav_count}. Total {ii + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886493b-16df-452e-8e96-5260af731091",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Signal Processing\n",
    "### key signature, tempo, chroma, zero crossing rate, MFCC (Mel-frequency cepstral coefficients), spectral bandwidth, RMSE (Root Mean Square Error), etc\n",
    "### I don't want to use a mood or genre classifier because it's a solved problem.\n",
    "### I'm instead going to attempt to extract this metadata from the raw audio\n",
    "### Then I'll calculate sonme distance score using all metadata and use it to match songs for recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0484f6b4-145a-45fa-bfc6-f048f7acb814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "Installing collected packages: soxr, audioread, soundfile, pooch, librosa\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [librosa]\n",
      "\u001b[1A\u001b[2KSuccessfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install librosa\n",
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "926bf9b5-786e-46e8-8d0d-8d37ab3e1a07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ii' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     37\u001b[39m         subprocess.run(command, stdout=f, shell=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     38\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33;03m    # Convert to Windows-style path\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    windows_wav_file = wav_file.replace(\"/mnt/c/\", \"C:/\").replace(\"/\", \"\\\\\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33;03m        #print(\"STDERR:\", result.stderr.decode())\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskip_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Converted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchord_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Total \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mii\u001b[49m\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'ii' is not defined"
     ]
    }
   ],
   "source": [
    "## Extract and Save Chord Progression to File\n",
    "## WARNING: Only works from Windows!!!\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Make sure chords folder exists\n",
    "#working_dir = '/mnt/c/Users/carja/Documents/Capstone/data/'\n",
    "working_dir = 'C:/Users/carja/Documents/Capstone/data/'\n",
    "wav_dir = working_dir + 'wavs'\n",
    "chords_dir = working_dir + 'chords'\n",
    "os.makedirs(chords_dir, exist_ok=True)\n",
    "\n",
    "# Loop over your DataFrame rows\n",
    "skip_count, chord_count = 0, 0\n",
    "for idx, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    wav_name = sanitize_filename(f\"{artist} - {track}.wav\")\n",
    "    wav_file = wav_dir + '/' + wav_name #os.path.join(wav_dir, wav_name)\n",
    "    chords_name = sanitize_filename(f\"{artist} - {track}.csv\")\n",
    "    chords_file = chords_dir + '/' + chords_name # os.path.join(chords_dir, chords_name)\n",
    "    \n",
    "     # ✅ Skip if file doesn't exists\n",
    "    if not os.path.exists(wav_file) or (os.path.exists(chords_file) and os.path.getsize(chords_file) > 0):\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    chord_count += 1\n",
    "\n",
    "    command = [\n",
    "        'C:/Sonic Annotator/sonic-annotator.exe',\n",
    "        '-d', 'vamp:nnls-chroma:chordino',\n",
    "        '-w', 'csv',\n",
    "        '--csv-stdout',\n",
    "        wav_file\n",
    "    ]\n",
    "\n",
    "    with open(chords_file, \"w\") as f:\n",
    "        subprocess.run(command, stdout=f, shell=True)\n",
    "    '''\n",
    "    # Convert to Windows-style path\n",
    "    windows_wav_file = wav_file.replace(\"/mnt/c/\", \"C:/\").replace(\"/\", \"\\\\\")\n",
    "    command = [\n",
    "        '/mnt/c/Sonic Annotator/sonic-annotator.exe',\n",
    "        '-d', 'vamp:nnls-chroma:chordino:chordnotes',\n",
    "        '-w', 'csv',\n",
    "        '--csv-stdout',\n",
    "        windows_wav_file\n",
    "    ]\n",
    "    \n",
    "    # Run and capture output\n",
    "    with open(chords_file, \"w\") as f:\n",
    "        subprocess.run(command, stdout=f)\n",
    "        #result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "        #print(\"STDOUT:\", result.stdout.decode())\n",
    "        #print(\"STDERR:\", result.stderr.decode())\n",
    "    '''\n",
    "\n",
    "print(f\"Skipped {skip_count}. Converted {chord_count}. Total {ii + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddef9df-4980-4ebc-86c4-1a1a1a40c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analyze With Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38234f1e-da5e-436d-a14b-d21b9ce916b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Processing chunk 0–100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f2238978b20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f2238978b20>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 171\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39mMAX_WORKERS) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 171\u001b[0m         futures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43manalyze_song\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing batch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24/lib/python3.10/concurrent/futures/process.py:575\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    576\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/rapids-24/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Append Audio Information to df\n",
    "#\n",
    "### librosa: https://librosa.org/doc/latest/index.html\n",
    "### (McFee, Brian, Colin Raffel, Dawen Liang, Daniel PW Ellis, Matt McVicar, Eric Battenberg, and Oriol Nieto.\n",
    "### “librosa: Audio and music signal analysis in python.” In Proceedings of the 14th python in science conference, pp. 18-25. 2015.)\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "from time import time\n",
    "import traceback\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "### To make this run as stand-alone .py script for performance ###\n",
    "### Load the playlist into df ###\n",
    "\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Remove characters not allowed in filenames (Windows, macOS, Linux)\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', '', filename)\n",
    "\n",
    "\"\"\" Degree of Harmony\n",
    "    1.0–1.5 → monophonic (no harmony, single note per time).\n",
    "    2.0–3.0 → likely vocal harmonies or chords (e.g., duets, backing vocals).\n",
    "    3.0 → rich harmonic content (dense vocals, synths, or polyphonic instruments).\n",
    "\"\"\"\n",
    "def detectDegreeOfHarmony(chroma):\n",
    "    threshold = 0.5 * chroma.max(axis=0) # Define a threshold as a fraction of the maximum chroma energy\n",
    "    strong = (chroma >= threshold)\n",
    "    return np.mean(strong.sum(axis=0))\n",
    "\n",
    "\n",
    "# Krumhansl-Schmuckler key profiles\n",
    "major_profile = [6.35, 2.23, 3.48, 2.33, 4.38, 4.09,\n",
    "                 2.52, 5.19, 2.39, 3.66, 2.29, 2.88]\n",
    "minor_profile = [6.33, 2.68, 3.52, 5.38, 2.60, 3.53,\n",
    "                 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]\n",
    "# Rotate profiles to each of the 12 keys\n",
    "profiles, key_names = [], []\n",
    "# Major keys\n",
    "for i in range(12):\n",
    "    profiles.append(np.roll(major_profile, i))\n",
    "    key_names.append(librosa.midi_to_note(60 + i, octave=False) + ' major')\n",
    "# Minor keys\n",
    "for i in range(12):\n",
    "    profiles.append(np.roll(minor_profile, i))\n",
    "    key_names.append(librosa.midi_to_note(60 + i, octave=False) + ' minor')\n",
    "# end\n",
    "\n",
    "\n",
    "def analyze_song(args):\n",
    "    index, row, mp3_dir = args\n",
    "    try:\n",
    "        artist = row['artist_name']\n",
    "        track = row['track_name']\n",
    "        safe_name = f\"{artist} - {track}.mp3\".replace(\"/\", \"-\").replace(\":\", \"-\")\n",
    "        song_file = os.path.join(mp3_dir, safe_name) #mp3_dir + '/' + safe_name\n",
    "    \n",
    "        if not os.path.exists(song_file):\n",
    "            return -1, None  # Mark as skipped\n",
    "\n",
    "        result = {}\n",
    "    \n",
    "        y, sr = librosa.load(song_file)\n",
    "        chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    \n",
    "        # Harmony\n",
    "        result['harmony_degree'] = detectDegreeOfHarmony(chroma)\n",
    "    \n",
    "        # Key estimation\n",
    "        chroma_mean = np.mean(chroma, axis=1)\n",
    "        correlations = [np.corrcoef(chroma_mean, profile)[0, 1] for profile in profiles]\n",
    "        best_index = np.argmax(correlations)\n",
    "    \n",
    "        estimated_key = key_names[best_index]\n",
    "        key_str = estimated_key.replace(\"♯\", \"#\").replace(\"♭\", \"b\")  # Change this to your key\n",
    "        tonic, mode = key_str.split()\n",
    "        result['tonic'] = tonic\n",
    "        result['mode'] = mode\n",
    "\n",
    "\n",
    "        # Tempo\n",
    "        tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "        result['tempo'] = float(np.squeeze(tempo))\n",
    "    \n",
    "        # MFCC\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "        result['mfcc_shape'] = str(mfccs.shape)\n",
    "    \n",
    "        # Spectral features\n",
    "        spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "        result['spectral_contrast_mean'] = np.mean(spectral_contrast)\n",
    "        result['spectral_contrast_var'] = np.std(spectral_contrast)\n",
    "    \n",
    "        spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "        result['spectral_centroid_mean'] = np.mean(spectral_centroid)\n",
    "        result['spectral_centroid_var'] = np.std(spectral_centroid)\n",
    "    \n",
    "        spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "        result['spectral_flatness_mean'] = np.mean(spectral_flatness)\n",
    "        result['spectral_flatness_var'] = np.std(spectral_flatness)\n",
    "    \n",
    "        return index, result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {index}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return -1, None\n",
    "\n",
    "\n",
    "\n",
    "# Load JSON from file ############################\n",
    "#working_dir = 'C:/Users/carja/Documents/Capstone/data/'\n",
    "working_dir = '/mnt/c/Users/carja/Documents/Capstone/data/'\n",
    "with open(working_dir + 'playlist_data3.json', encoding='utf-8') as f:\n",
    "    playlists  = json.load(f)\n",
    "\n",
    "# Flattened track list\n",
    "track_rows = []\n",
    "\n",
    "for playlist in playlists:\n",
    "    # Extract playlist metadata (everything except the track list)\n",
    "    playlist_metadata = {k: v for k, v in playlist.items() if k != '0'}\n",
    "    \n",
    "    # Extract the track list (the key \"0\" holds the tracks)\n",
    "    tracks = playlist.get(\"0\", [])\n",
    "    \n",
    "    for track in tracks:\n",
    "        # Combine track data with playlist metadata\n",
    "        combined = {**track, **playlist_metadata}\n",
    "        track_rows.append(combined)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(track_rows)\n",
    "# Rename playlist fields to make it clear\n",
    "playlist_fields = ['name', 'pid', 'num_tracks', 'num_albums', 'num_artists', 'num_followers', 'collaborative']\n",
    "df.rename(columns={field: f'playlist_{field}' for field in playlist_fields}, inplace=True)\n",
    "# first remove duplicate tracks to avoid downloading twice\n",
    "df = df.drop_duplicates(subset=['artist_name', 'track_name'])\n",
    "############################\n",
    "\n",
    "\n",
    "# Loop over your DataFrame rows\n",
    "mp3_dir = working_dir + 'downloads'\n",
    "results = []\n",
    "\n",
    "chunk_size = 100  # Adjust based on memory, speed, etc.\n",
    "total = len(df)\n",
    "MAX_WORKERS = os.cpu_count() - 1  # Use all cores except one for stability\n",
    "for start in range(0, total, chunk_size):\n",
    "    end = min(start + chunk_size, total)\n",
    "    batch = df.iloc[start:end]\n",
    "\n",
    "    tasks = [(idx, row, mp3_dir) for idx, row in batch.iterrows()]\n",
    "    print(f\"\\n🔹 Processing chunk {start}–{end}...\")\n",
    "\n",
    "    # Timing each chunk\n",
    "    t0 = time()\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        try:\n",
    "            futures = list(executor.map(analyze_song, tasks))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "    t1 = time()\n",
    "\n",
    "    # Collect results\n",
    "    chunk_results = [res for res in futures if res is not None and res[0] >= 0]\n",
    "    results.extend(chunk_results)\n",
    "\n",
    "    print(f\"⏱️ Completed in {t1 - t0:.2f} seconds. Saving checkpoint...\")\n",
    "\n",
    "    # Save intermediate result\n",
    "    partial_df = pd.DataFrame([r[1] for r in chunk_results], index=[r[0] for r in chunk_results])\n",
    "    partial_df.sort_index(inplace=True)\n",
    "    checkpoint_file = os.path.join(working_dir, f'checkpoint_{start}_{end}.csv')\n",
    "    partial_df.to_csv(checkpoint_file)\n",
    "\n",
    "# Final save\n",
    "if results:\n",
    "    final_df = pd.DataFrame([r[1] for r in results], index=[r[0] for r in results])\n",
    "    final_df = df.join(final_df, how='left')\n",
    "    final_df.to_csv(os.path.join(working_dir, 'initialAnalysis.csv'), index=False)\n",
    "\n",
    "print(\"✅ All chunks processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93de6416-1d47-4e99-a7e6-a947054557d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>pos</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_pid</th>\n",
       "      <th>playlist_num_tracks</th>\n",
       "      <th>playlist_num_albums</th>\n",
       "      <th>playlist_num_artists</th>\n",
       "      <th>...</th>\n",
       "      <th>tonic</th>\n",
       "      <th>mode</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mfcc_shape</th>\n",
       "      <th>spectral_contrast_mean</th>\n",
       "      <th>spectral_contrast_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_flatness_mean</th>\n",
       "      <th>spectral_flatness_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How I Feel</td>\n",
       "      <td>0</td>\n",
       "      <td>How I Feel</td>\n",
       "      <td>Flo Rida</td>\n",
       "      <td>169557</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>major</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>(13, 7656)</td>\n",
       "      <td>21.106346</td>\n",
       "      <td>11.337712</td>\n",
       "      <td>2640.301228</td>\n",
       "      <td>890.561052</td>\n",
       "      <td>0.083839</td>\n",
       "      <td>0.205738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lo Que No Sabes Tú</td>\n",
       "      <td>1</td>\n",
       "      <td>Mi Niña Bonita - Reloaded</td>\n",
       "      <td>Chino &amp; Nacho</td>\n",
       "      <td>232120</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>major</td>\n",
       "      <td>161.499023</td>\n",
       "      <td>(13, 10429)</td>\n",
       "      <td>21.820560</td>\n",
       "      <td>11.282618</td>\n",
       "      <td>2693.961413</td>\n",
       "      <td>1082.618798</td>\n",
       "      <td>0.036503</td>\n",
       "      <td>0.072091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chucuchá</td>\n",
       "      <td>2</td>\n",
       "      <td>El Sonido</td>\n",
       "      <td>Ilegales</td>\n",
       "      <td>206959</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>(13, 9565)</td>\n",
       "      <td>21.415842</td>\n",
       "      <td>11.880545</td>\n",
       "      <td>2628.981838</td>\n",
       "      <td>809.000785</td>\n",
       "      <td>0.048472</td>\n",
       "      <td>0.124956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mueva la colita</td>\n",
       "      <td>3</td>\n",
       "      <td>Top Caribe</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>242373</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>minor</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>(13, 10439)</td>\n",
       "      <td>21.660702</td>\n",
       "      <td>11.768187</td>\n",
       "      <td>3254.803701</td>\n",
       "      <td>926.430375</td>\n",
       "      <td>0.066690</td>\n",
       "      <td>0.099132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Be My Baby</td>\n",
       "      <td>4</td>\n",
       "      <td>Lloviendo Estrellas</td>\n",
       "      <td>Leslie Grace</td>\n",
       "      <td>218253</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>E</td>\n",
       "      <td>major</td>\n",
       "      <td>135.999178</td>\n",
       "      <td>(13, 9648)</td>\n",
       "      <td>23.254460</td>\n",
       "      <td>10.982775</td>\n",
       "      <td>2546.516052</td>\n",
       "      <td>884.615807</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>0.126105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           track_name  pos                 album_name      artist_name  \\\n",
       "0          How I Feel    0                 How I Feel         Flo Rida   \n",
       "1  Lo Que No Sabes Tú    1  Mi Niña Bonita - Reloaded    Chino & Nacho   \n",
       "2            Chucuchá    2                  El Sonido         Ilegales   \n",
       "3     Mueva la colita    3                 Top Caribe  Various Artists   \n",
       "4          Be My Baby    4        Lloviendo Estrellas     Leslie Grace   \n",
       "\n",
       "   duration_ms playlist_name playlist_pid  playlist_num_tracks  \\\n",
       "0       169557          2014            8                   21   \n",
       "1       232120          2014            8                   21   \n",
       "2       206959          2014            8                   21   \n",
       "3       242373          2014            8                   21   \n",
       "4       218253          2014            8                   21   \n",
       "\n",
       "   playlist_num_albums  playlist_num_artists  ...  tonic   mode       tempo  \\\n",
       "0                   21                    19  ...      F  major  129.199219   \n",
       "1                   21                    19  ...      A  major  161.499023   \n",
       "2                   21                    19  ...      A  minor  143.554688   \n",
       "3                   21                    19  ...      A  minor  143.554688   \n",
       "4                   21                    19  ...      E  major  135.999178   \n",
       "\n",
       "    mfcc_shape spectral_contrast_mean  spectral_contrast_var  \\\n",
       "0   (13, 7656)              21.106346              11.337712   \n",
       "1  (13, 10429)              21.820560              11.282618   \n",
       "2   (13, 9565)              21.415842              11.880545   \n",
       "3  (13, 10439)              21.660702              11.768187   \n",
       "4   (13, 9648)              23.254460              10.982775   \n",
       "\n",
       "  spectral_centroid_mean  spectral_centroid_var  spectral_flatness_mean  \\\n",
       "0            2640.301228             890.561052                0.083839   \n",
       "1            2693.961413            1082.618798                0.036503   \n",
       "2            2628.981838             809.000785                0.048472   \n",
       "3            3254.803701             926.430375                0.066690   \n",
       "4            2546.516052             884.615807                0.038849   \n",
       "\n",
       "   spectral_flatness_var  \n",
       "0               0.205738  \n",
       "1               0.072091  \n",
       "2               0.124956  \n",
       "3               0.099132  \n",
       "4               0.126105  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load saved progress\n",
    "#import pandas as pd\n",
    "#df = pd.read_csv(working_dir + 'initialAnalysis.csv')\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4e65c-726b-4c91-aa92-732653de165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify Chord Progress\n",
    "## Get Tonic from Key\n",
    "## Mod based on Tonic\n",
    "## Save \"factorized\" progression pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8208e66a-2bc9-44bb-a354-afedfa8555d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting music21==6.1.0\n",
      "  Downloading music21-6.1.0.tar.gz (18.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting chardet (from music21==6.1.0)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: joblib in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from music21==6.1.0) (1.5.1)\n",
      "Collecting more-itertools (from music21==6.1.0)\n",
      "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: webcolors in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from music21==6.1.0) (24.11.1)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: music21\n",
      "\u001b[33m  DEPRECATION: Building 'music21' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'music21'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for music21 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for music21: filename=music21-6.1.0-py3-none-any.whl size=20946288 sha256=272d077522f3f7e3d0b9b088acb10435841e3a7e6a5770613f84aeedf52ae8dd\n",
      "  Stored in directory: /home/carjam/.cache/pip/wheels/e3/4a/e8/45178c0f2a49d5989fc8a12d30e1ccc0a9fc01151835b566a4\n",
      "Successfully built music21\n",
      "Installing collected packages: more-itertools, chardet, music21\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [music21]m2/3\u001b[0m [music21]\n",
      "\u001b[1A\u001b[2KSuccessfully installed chardet-5.2.0 more-itertools-10.7.0 music21-6.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install music21==6.1.0 --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "457416c2-d7ba-4375-8256-f44f97a12bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   0%|                                                                        | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 800: 'float' object has no attribute 'lower'\n",
      "Error processing index 1300: 'float' object has no attribute 'lower'\n",
      "Error processing index 100: 'float' object has no attribute 'lower'\n",
      "Error processing index 1100: 'float' object has no attribute 'lower'\n",
      "Error processing index 801: 'float' object has no attribute 'lower'\n",
      "Error processing index 101: 'float' object has no attribute 'lower'\n",
      "Error processing index 102: 'float' object has no attribute 'lower'\n",
      "Error processing index 103: 'float' object has no attribute 'lower'\n",
      "Error processing index 104: 'float' object has no attribute 'lower'\n",
      "Error processing index 105: 'float' object has no attribute 'lower'\n",
      "Error processing index 106: 'float' object has no attribute 'lower'\n",
      "Error processing index 107: 'float' object has no attribute 'lower'\n",
      "Error processing index 400: 'float' object has no attribute 'lower'\n",
      "Error processing index 401: 'float' object has no attribute 'lower'\n",
      "Error processing index 402: 'float' object has no attribute 'lower'\n",
      "Error processing index 403: 'float' object has no attribute 'lower'\n",
      "Error processing index 404: 'float' object has no attribute 'lower'\n",
      "Error processing index 405: 'float' object has no attribute 'lower'\n",
      "Error processing index 406: 'float' object has no attribute 'lower'\n",
      "Error processing index 202: 'float' object has no attribute 'lower'\n",
      "Error processing index 109: 'float' object has no attribute 'lower'\n",
      "Error processing index 110: 'float' object has no attribute 'lower'\n",
      "Error processing index 111: 'float' object has no attribute 'lower'\n",
      "Error processing index 112: 'float' object has no attribute 'lower'\n",
      "Error processing index 113: 'float' object has no attribute 'lower'\n",
      "Error processing index 114: 'float' object has no attribute 'lower'\n",
      "Error processing index 115: 'float' object has no attribute 'lower'\n",
      "Error processing index 118: 'float' object has no attribute 'lower'\n",
      "Error processing index 609: 'float' object has no attribute 'lower'\n",
      "Error processing index 124: 'float' object has no attribute 'lower'\n",
      "Error processing index 508: 'float' object has no attribute 'lower'\n",
      "Error processing index 815: 'float' object has no attribute 'lower'\n",
      "Error processing index 816: 'float' object has no attribute 'lower'\n",
      "Error processing index 817: 'float' object has no attribute 'lower'\n",
      "Error processing index 818: 'float' object has no attribute 'lower'\n",
      "Error processing index 819: 'float' object has no attribute 'lower'\n",
      "Error processing index 820: 'float' object has no attribute 'lower'\n",
      "Error processing index 1213: 'float' object has no attribute 'lower'\n",
      "Error processing index 614: 'float' object has no attribute 'lower'\n",
      "Error processing index 1215: 'float' object has no attribute 'lower'\n",
      "Error processing index 1120: 'float' object has no attribute 'lower'\n",
      "Error processing index 215: 'float' object has no attribute 'lower'\n",
      "Error processing index 519: 'float' object has no attribute 'lower'\n",
      "Error processing index 1018: 'float' object has no attribute 'lower'\n",
      "Error processing index 217: 'float' object has no attribute 'lower'\n",
      "Error processing index 219: 'float' object has no attribute 'lower'\n",
      "Error processing index 220: 'float' object has no attribute 'lower'\n",
      "Error processing index 1318: 'float' object has no attribute 'lower'\n",
      "Error processing index 1225: 'float' object has no attribute 'lower'\n",
      "Error processing index 1420: 'float' object has no attribute 'lower'\n",
      "Error processing index 525: 'float' object has no attribute 'lower'\n",
      "Error processing index 921: 'float' object has no attribute 'lower'\n",
      "Error processing index 26: 'float' object has no attribute 'lower'\n",
      "Error processing index 1328: 'float' object has no attribute 'lower'\n",
      "Error processing index 1329: 'float' object has no attribute 'lower'\n",
      "Error processing index 230: 'float' object has no attribute 'lower'\n",
      "Error processing index 34: 'float' object has no attribute 'lower'\n",
      "Error processing index 232: 'float' object has no attribute 'lower'\n",
      "Error processing index 444: 'float' object has no attribute 'lower'\n",
      "Error processing index 847: 'float' object has no attribute 'lower'\n",
      "Error processing index 235: 'float' object has no attribute 'lower'\n",
      "Error processing index 38: 'float' object has no attribute 'lower'\n",
      "Error processing index 237: 'float' object has no attribute 'lower'\n",
      "Error processing index 849: 'float' object has no attribute 'lower'\n",
      "Error processing index 239: 'float' object has no attribute 'lower'\n",
      "Error processing index 645: 'float' object has no attribute 'lower'\n",
      "Error processing index 648: 'float' object has no attribute 'lower'\n",
      "Error processing index 649: 'float' object has no attribute 'lower'\n",
      "Error processing index 650: 'float' object has no attribute 'lower'\n",
      "Error processing index 651: 'float' object has no attribute 'lower'\n",
      "Error processing index 652: 'float' object has no attribute 'lower'\n",
      "Error processing index 653: 'float' object has no attribute 'lower'\n",
      "Error processing index 247: 'float' object has no attribute 'lower'\n",
      "Error processing index 655: 'float' object has no attribute 'lower'\n",
      "Error processing index 658: 'float' object has no attribute 'lower'\n",
      "Error processing index 660: 'float' object has no attribute 'lower'\n",
      "Error processing index 860: 'float' object has no attribute 'lower'\n",
      "Error processing index 861: 'float' object has no attribute 'lower'\n",
      "Error processing index 664: 'float' object has no attribute 'lower'\n",
      "Error processing index 1154: 'float' object has no attribute 'lower'\n",
      "Error processing index 1056: 'float' object has no attribute 'lower'\n",
      "Error processing index 1352: 'float' object has no attribute 'lower'\n",
      "Error processing index 1446: 'float' object has no attribute 'lower'\n",
      "Error processing index 866: 'float' object has no attribute 'lower'\n",
      "Error processing index 1158: 'float' object has no attribute 'lower'\n",
      "Error processing index 868: 'float' object has no attribute 'lower'\n",
      "Error processing index 1160: 'float' object has no attribute 'lower'\n",
      "Error processing index 558: 'float' object has no attribute 'lower'\n",
      "Error processing index 1165: 'float' object has no attribute 'lower'\n",
      "Error processing index 362: 'float' object has no attribute 'lower'\n",
      "Error processing index 871: 'float' object has no attribute 'lower'\n",
      "Error processing index 1454: 'float' object has no attribute 'lower'\n",
      "Error processing index 1168: 'float' object has no attribute 'lower'\n",
      "Error processing index 1169: 'float' object has no attribute 'lower'\n",
      "Error processing index 175: 'float' object has no attribute 'lower'\n",
      "Error processing index 1460: 'float' object has no attribute 'lower'\n",
      "Error processing index 569: 'float' object has no attribute 'lower'\n",
      "Error processing index 1174: 'float' object has no attribute 'lower'\n",
      "Error processing index 367: 'float' object has no attribute 'lower'\n",
      "Error processing index 179: 'float' object has no attribute 'lower'\n",
      "Error processing index 180: 'float' object has no attribute 'lower'\n",
      "Error processing index 370: 'float' object has no attribute 'lower'\n",
      "Error processing index 373: 'float' object has no attribute 'lower'\n",
      "Error processing index 964: 'float' object has no attribute 'lower'\n",
      "Error processing index 1182: 'float' object has no attribute 'lower'\n",
      "Error processing index 1080: 'float' object has no attribute 'lower'\n",
      "Error processing index 286: 'float' object has no attribute 'lower'\n",
      "Error processing index 1474: 'float' object has no attribute 'lower'\n",
      "Error processing index 1382: 'float' object has no attribute 'lower'\n",
      "Error processing index 1477: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:   7%|████▎                                                           | 1/15 [00:29<06:47, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 893: 'float' object has no attribute 'lower'\n",
      "Error processing index 293: 'float' object has no attribute 'lower'\n",
      "Error processing index 584: 'float' object has no attribute 'lower'\n",
      "Error processing index 975: 'float' object has no attribute 'lower'\n",
      "Error processing index 976: 'float' object has no attribute 'lower'\n",
      "Error processing index 586: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  13%|████████▌                                                       | 2/15 [00:30<02:47, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 981: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  20%|████████████▊                                                   | 3/15 [00:31<01:26,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 1391: 'float' object has no attribute 'lower'\n",
      "Error processing index 91: 'float' object has no attribute 'lower'\n",
      "Error processing index 92: 'float' object has no attribute 'lower'\n",
      "Error processing index 93: 'float' object has no attribute 'lower'\n",
      "Error processing index 94: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  27%|█████████████████                                               | 4/15 [00:31<00:50,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 97: 'float' object has no attribute 'lower'\n",
      "Error processing index 98: 'float' object has no attribute 'lower'\n",
      "Error processing index 99: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  33%|█████████████████████▎                                          | 5/15 [00:31<00:30,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 395: 'float' object has no attribute 'lower'\n",
      "Error processing index 396: 'float' object has no attribute 'lower'\n",
      "Error processing index 397: 'float' object has no attribute 'lower'\n",
      "Error processing index 398: 'float' object has no attribute 'lower'\n",
      "Error processing index 399: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  53%|██████████████████████████████████▏                             | 8/15 [00:32<00:08,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 1398: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  67%|██████████████████████████████████████████                     | 10/15 [00:33<00:04,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 1284: 'float' object has no attribute 'lower'\n",
      "Error processing index 785: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|██████████████████████████████████████████████████▍            | 12/15 [00:34<00:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 1288: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  87%|██████████████████████████████████████████████████████▌        | 13/15 [00:34<00:01,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 795: 'float' object has no attribute 'lower'\n",
      "Error processing index 796: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  93%|██████████████████████████████████████████████████████████▊    | 14/15 [00:36<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 1299: 'float' object has no attribute 'lower'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|███████████████████████████████████████████████████████████████| 15/15 [00:38<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1316 tracks out of 1480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from music21 import key as m21key, roman, chord, pitch, harmony\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "import re\n",
    "from typing import List, Tuple, Optional\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "from time import time\n",
    "import traceback\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "\n",
    "def cadence_bonus(pattern):\n",
    "    \"\"\"Add score based on how the pattern ends.\"\"\"\n",
    "    if len(pattern) < 2:\n",
    "        return 0\n",
    "\n",
    "    end = pattern[-2:]\n",
    "    last = pattern[-1]\n",
    "\n",
    "    # Strong cadences\n",
    "    if end == ['V', 'I'] or end == ['V7', 'I']:\n",
    "        return 8  # Authentic cadence\n",
    "    if end == ['IV', 'I']:\n",
    "        return 5  # Plagal cadence\n",
    "    if end == ['V', 'vi']:\n",
    "        return 3  # Deceptive cadence\n",
    "    if pattern[-3:] == ['ii', 'V', 'I']:\n",
    "        return 6  # 2-5-1 cadence\n",
    "    if pattern[-3:] == ['I', 'IV', 'V'] or pattern[-4:] == ['I', 'IV', 'V', 'I']:\n",
    "        return 6  # Full cadence\n",
    "    if pattern[-4:] == ['I', 'V', 'vi', 'IV']:\n",
    "        return 4  # Axis progression\n",
    "    if end == ['bVII', 'I']:\n",
    "        return 4  # Modal cadence (Mixolydian)\n",
    "\n",
    "    # Melodic feel resolutions\n",
    "    if last == 'I':\n",
    "        return 2  # Tonic resolution\n",
    "    if last == 'iii':\n",
    "        return 2  # Mediant (3rd) resolution\n",
    "    if last == 'vi':\n",
    "        return 1  # Submediant resolution\n",
    "\n",
    "    return 0\n",
    "\n",
    "'''\n",
    "    Searches the sequence for looped sequences. if none is found returns the most frequent patterns.\n",
    "    weights resolutions that resolve to the key\n",
    "    weights length to prevent \"greedy\" tendency of shorter sequences to dominate repetitions\n",
    "    reduces overlap in sequences by checking equality, subset, and intersection > min_len\n",
    "'''\n",
    "def is_subpattern(smaller, larger):\n",
    "    # Convert to strings with a delimiter to avoid partial matches across boundaries\n",
    "    delimiter = '|'\n",
    "    smaller_str = delimiter.join(smaller)\n",
    "    larger_str = delimiter.join(larger)\n",
    "    return smaller_str in larger_str\n",
    "\n",
    "def find_top_two_progression_patterns(progression, min_len, max_len):\n",
    "    n = len(progression)\n",
    "    pattern_counts = defaultdict(int)\n",
    "    pattern_positions = defaultdict(list)\n",
    "\n",
    "    # Identify all patterns and their positions\n",
    "    for i in range(n):\n",
    "        for length in range(min_len, max_len + 1):\n",
    "            if i + length <= n:\n",
    "                pattern = tuple(progression[i:i + length])\n",
    "                pattern_counts[pattern] += 1\n",
    "                pattern_positions[pattern].append((i, i + length))  # store as (start, end)\n",
    "       \n",
    "    scored_patterns = []\n",
    "    for pattern, positions in pattern_positions.items():\n",
    "        last_chord = pattern[-1]\n",
    "        resolution_bonus = cadence_bonus(pattern)\n",
    "\n",
    "        # Check for strict looping\n",
    "        is_looping = False\n",
    "        if len(positions) > 1:\n",
    "            distances = [j[0] - i[0] for i, j in zip(positions, positions[1:])]\n",
    "            if all(d == len(pattern) for d in distances):\n",
    "                is_looping = True\n",
    "\n",
    "        base_score = len(pattern) + resolution_bonus if is_looping else pattern_counts[pattern] * len(pattern) + resolution_bonus\n",
    "        scored_patterns.append((base_score, pattern, pattern_counts[pattern], positions))\n",
    "\n",
    "    # Sort by score descending\n",
    "    scored_patterns.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    top_matches = []\n",
    "\n",
    "    for score, pattern, count, positions in scored_patterns:\n",
    "        pattern_list = list(pattern)\n",
    "\n",
    "        # Check against previously selected patterns\n",
    "        is_valid = True\n",
    "        for existing in top_matches:\n",
    "            # Subset/duplicate check\n",
    "            if (\n",
    "                pattern == tuple(existing['pattern']) or\n",
    "                is_subpattern(pattern, existing['pattern']) or\n",
    "                is_subpattern(existing['pattern'], pattern)\n",
    "            ):\n",
    "                is_valid = False\n",
    "                break\n",
    "\n",
    "            # Overlap check\n",
    "            for p_start, p_end in positions:\n",
    "                for e_start, e_end in existing['positions']:\n",
    "                    overlap = max(0, min(p_end, e_end) - max(p_start, e_start))\n",
    "                    if overlap > min_len:\n",
    "                        is_valid = False\n",
    "                        break\n",
    "                if not is_valid:\n",
    "                    break\n",
    "\n",
    "        if is_valid:\n",
    "            top_matches.append({\n",
    "                \"pattern\": pattern_list,\n",
    "                \"repetitions\": count,\n",
    "                \"positions\": positions\n",
    "            })\n",
    "\n",
    "        if len(top_matches) == 2:\n",
    "            break\n",
    "\n",
    "    # Remove 'positions' before returning if not needed\n",
    "    for match in top_matches:\n",
    "        del match['positions']\n",
    "\n",
    "    return top_matches\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Remove characters not allowed in filenames (Windows, macOS, Linux)\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', '', filename)\n",
    "\n",
    "# currently only supports chordino format (3 columns).\n",
    "# The newer chordnotes format (4 columns) is more precise\n",
    "# but requires transforming MIDI to notes based on confidence levels\n",
    "# then splicing the notes together to make chords\n",
    "def read_chords_file(chords_file):\n",
    "    # Read without header, ignore comment lines\n",
    "    df_chord = pd.read_csv(chords_file, comment=\"#\", header=None)\n",
    "    \n",
    "    if df_chord.shape[1] == 3:\n",
    "        df_chord.columns = [\"start\", \"duration\", \"chord\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected number of columns: {df_chord.shape[1]} in {chords_file}\")\n",
    "    \n",
    "    return df_chord[\"chord\"]\n",
    "\n",
    "# Simplify chords\n",
    "def clean_chord(ch):\n",
    "    # Only use base chord (before colon) and strip whitespace\n",
    "    return ch.split(\":\")[0].strip()\n",
    "\n",
    "def normalize_chord_symbol(ch_str):\n",
    "    # Split bass note off\n",
    "    base = ch_str.split('/')[0]\n",
    "    \n",
    "    # Replace unicode flats '♭' with 'b'\n",
    "    base = base.replace(\"♭\", \"b\")\n",
    "    # Replace flats 'b' that occur immediately after a note letter with '-'\n",
    "    # e.g. 'Eb7' -> 'E-7'\n",
    "    # Pattern: letter followed by 'b'\n",
    "    base = re.sub(r'([A-Ga-g])b', r'\\1-', base)\n",
    "    \n",
    "    # Replace unicode sharps '♯' with '#'\n",
    "    base = base.replace('♯', '#')\n",
    "    \n",
    "    # Recombine with bass if present\n",
    "    if '/' in ch_str:\n",
    "        bass = ch_str.split('/')[1]\n",
    "        return base + '/' + bass\n",
    "    else:\n",
    "        return base\n",
    "\n",
    "def simplify_to_triad(chord_str: str):\n",
    "    try:\n",
    "        chord_str.closedPosition(forceOctave=4, inPlace=True)\n",
    "        root = chord_str.root()\n",
    "        quality = chord_str.commonName\n",
    "        \n",
    "        # ✅ Check root and quality are both valid strings or objects\n",
    "        if not root or not isinstance(quality, str):\n",
    "            return None\n",
    "        \n",
    "        # ✅ Safely apply .lower()\n",
    "        q = quality.lower()\n",
    "        \n",
    "        # Decide triad type based on commonName\n",
    "        if \"major\" in q:\n",
    "            return harmony.ChordSymbol(f\"{root.name}\")\n",
    "        elif \"minor\" in q:\n",
    "            return harmony.ChordSymbol(f\"{root.name}m\")\n",
    "        elif \"diminished\" in q or \"dim\" in q:\n",
    "            return harmony.ChordSymbol(f\"{root.name}dim\")\n",
    "        elif \"augmented\" in q or \"aug\" in q:\n",
    "            return harmony.ChordSymbol(f\"{root.name}aug\")\n",
    "        else:\n",
    "            return harmony.ChordSymbol(root.name)  # Default to major if unclear\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to simplify {chord_str}: {e}\")\n",
    "        return None\n",
    "\n",
    "'''\n",
    "    Map chords to Roman numerals \n",
    "    We first simplify the chords to their triads\n",
    "    This makes pattern recognition stronger by de-emphasizing embelishments\n",
    "'''\n",
    "def chord_to_roman(chord_symbol, song_key):\n",
    "        try:\n",
    "            # Try parsing with ChordSymbol (handles complex symbols better)\n",
    "            cs = harmony.ChordSymbol(chord_symbol)\n",
    "            # This sometimes returns no pitches if parsing failed, check:\n",
    "            if not cs.pitches:\n",
    "                raise ValueError(f\"No pitches parsed for chord '{chord_symbol}'\")\n",
    "            triad = simplify_to_triad(cs)\n",
    "            rn = roman.romanNumeralFromChord(triad, song_key)\n",
    "            return rn.figure\n",
    "        except Exception as e:\n",
    "            # As fallback, try parsing just root note and quality manually\n",
    "            try:\n",
    "                # Remove bass note (after slash)\n",
    "                base_chord = chord_symbol.split('/')[0]\n",
    "                cs = harmony.ChordSymbol(base_chord)\n",
    "                triad = simplify_to_triad(cs)\n",
    "                rn = roman.romanNumeralFromChord(triad, song_key)\n",
    "                return rn.figure\n",
    "            except Exception as e2:\n",
    "                print(f\"Failed to convert '{chord_symbol}': {e2}\")\n",
    "                return None\n",
    "\n",
    "def process_song_chunk(chunk, chords_dir):\n",
    "    results = []\n",
    "    for ii, row in chunk.iterrows():\n",
    "        artist = row['artist_name']\n",
    "        track = row['track_name']\n",
    "        chords_name = sanitize_filename(f\"{artist} - {track}.csv\")\n",
    "        chords_file = os.path.join(chords_dir, chords_name)\n",
    "        \n",
    "        # Skip if file missing or empty\n",
    "        if not os.path.exists(chords_file) or os.path.getsize(chords_file) <= 0:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            chords = read_chords_file(chords_file)\n",
    "            chords_clean = [clean_chord(ch) for ch in chords if ch != \"N\"]\n",
    "            normal_chords = [normalize_chord_symbol(ch) for ch in chords_clean if ch != \"N\"]\n",
    "\n",
    "            song_key = m21key.Key(row[\"tonic\"], row[\"mode\"])\n",
    "            roman_chords = [chord_to_roman(ch, song_key) for ch in normal_chords]\n",
    "            roman_chords = [rc for rc in roman_chords if rc is not None]\n",
    "\n",
    "            sequences = find_top_two_progression_patterns(roman_chords, 4, 8)\n",
    "            result = {\n",
    "                'index': ii,\n",
    "                'progression1': sequences[0]['pattern'] if len(sequences) > 0 else None,\n",
    "                'progression2': sequences[1]['pattern'] if len(sequences) > 1 else None\n",
    "            }\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {ii}: {e}\")\n",
    "    return results\n",
    "\n",
    "########\n",
    "working_dir = '/mnt/c/Users/carja/Documents/Capstone/data/'\n",
    "\n",
    "## Load saved progress\n",
    "df = pd.read_csv(working_dir + 'initialAnalysis.csv')\n",
    "\n",
    "chords_dir = working_dir + 'chords'\n",
    "\n",
    "# --- Multiprocessing Setup ---\n",
    "def batch_dataframe(df, batch_size):\n",
    "    for start in range(0, len(df), batch_size):\n",
    "        yield df.iloc[start:start + batch_size]\n",
    "\n",
    "# --- Main Execution ---\n",
    "batch_size = 100\n",
    "df_batches = list(batch_dataframe(df, batch_size))\n",
    "MAX_WORKERS = os.cpu_count() - 1  # Use all cores except one for stability\n",
    "all_results = []\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "    try:\n",
    "        futures = [executor.submit(process_song_chunk, chunk, chords_dir) for chunk in df_batches]\n",
    "\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"Processing batches\"):\n",
    "            res = future.result()\n",
    "            if res:\n",
    "                all_results.extend(res)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch: {e}\")\n",
    "\n",
    "# --- Merge Results ---\n",
    "results_df = pd.DataFrame(all_results).set_index('index')\n",
    "for col in ['progression1', 'progression2']:\n",
    "    df.loc[results_df.index, col] = results_df[col]\n",
    "\n",
    "# --- Final Output ---\n",
    "print(f\"Processed {len(results_df)} tracks out of {len(df)}\")\n",
    "df.to_csv(working_dir + 'analyzedTracks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d737340-ff4e-433b-ac14-08573774c787",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 55.905606,
   "end_time": "2021-10-26T11:23:57.027692",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-26T11:23:01.122086",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
