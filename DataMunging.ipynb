{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cae37d80",
   "metadata": {
    "id": "cae37d80",
    "papermill": {
     "duration": 0.084616,
     "end_time": "2021-10-26T11:23:10.119772",
     "exception": false,
     "start_time": "2021-10-26T11:23:10.035156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install & Import Standard Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9300d9e-1a4b-4421-a9b6-2e62b55bad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (25.1.1)\n",
      "Requirement already satisfied: matplotlib in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Collecting https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
      "  Downloading https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
      "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m2.8 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: yt-dlp\n",
      "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yt-dlp: filename=yt_dlp-2025.5.22-py3-none-any.whl size=3005023 sha256=065f46a7495fbc417eaafcc5d2507cb19c3f4ed38ea3a138a6a9315cb282268a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n12nsiv1/wheels/4c/91/d1/c5369304e2f7afb660bb6eee093af5a7d3c0ea05a3c1e8c797\n",
      "Successfully built yt-dlp\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.5.22\n",
      "Requirement already satisfied: pandas in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install matplotlib\n",
    "#!pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
    "#!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994f5622",
   "metadata": {
    "id": "994f5622",
    "papermill": {
     "duration": 0.103147,
     "end_time": "2021-10-26T11:23:10.309708",
     "exception": false,
     "start_time": "2021-10-26T11:23:10.206561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# https://pypi.org/project/yt-dlp/\n",
    "import json\n",
    "import yt_dlp\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb8b77-bff7-4131-8086-0d4f3ab528c7",
   "metadata": {},
   "source": [
    "## Import Playlist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f90ada8e-3451-42b6-af85-71188d9c0eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting spotipy\n",
      "  Downloading spotipy-2.25.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting redis>=3.5.3 (from spotipy)\n",
      "  Downloading redis-6.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\carja\\appdata\\roaming\\python\\python313\\site-packages (from spotipy) (2.32.3)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\carja\\appdata\\roaming\\python\\python313\\site-packages (from spotipy) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\carja\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.25.0->spotipy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carja\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.25.0->spotipy) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carja\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.25.0->spotipy) (2025.4.26)\n",
      "Downloading spotipy-2.25.1-py3-none-any.whl (31 kB)\n",
      "Downloading redis-6.1.0-py3-none-any.whl (273 kB)\n",
      "Installing collected packages: redis, spotipy\n",
      "\n",
      "   ---------------------------------------- 0/2 [redis]\n",
      "   ---------------------------------------- 2/2 [spotipy]\n",
      "\n",
      "Successfully installed redis-6.1.0 spotipy-2.25.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install spotipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193eeed5-41d6-4c14-a0c1-4fc064e3a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download my daughter's playlist from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f260917-e177-421e-b809-9a43523e2564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://developer.spotify.com/dashboard/7d18709cd0cd4c3594689384206d4ac6\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import json\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id='###',\n",
    "    client_secret='###',\n",
    "    redirect_uri='http://127.0.0.1:8889/callback',\n",
    "    scope=\"playlist-read-private\"\n",
    "))\n",
    "\n",
    "#Emma's songs\n",
    "playlist_id = '1eZmS24ui4yIpg0SKOs7oV' \n",
    "results = sp.playlist(playlist_id)\n",
    "\n",
    "with open(\"emmas_playlist.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f0d06-b815-4cb0-85f5-ffee9683bf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data necessary to add it to the other playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e120f5b4-ceff-436b-b490-84d111e61000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load your downloaded JSON file\n",
    "with open(\"emmas_playlist.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract general playlist info\n",
    "playlist_info = {\n",
    "    \"name\": data[\"name\"],\n",
    "    \"pid\": 42,  # You can change or generate this if needed\n",
    "    \"num_tracks\": len(data[\"tracks\"][\"items\"]),\n",
    "    \"num_albums\": len(set(item[\"track\"][\"album\"][\"name\"] for item in data[\"tracks\"][\"items\"])),\n",
    "    \"num_artists\": len(set(artist[\"name\"]\n",
    "                           for item in data[\"tracks\"][\"items\"]\n",
    "                           for artist in item[\"track\"][\"artists\"])),\n",
    "    \"num_followers\": data.get(\"followers\", {}).get(\"total\", 0),\n",
    "    \"collaborative\": str(data.get(\"collaborative\", False)).lower(),\n",
    "    \"0\": []\n",
    "}\n",
    "\n",
    "# Add each track\n",
    "for idx, item in enumerate(data[\"tracks\"][\"items\"]):\n",
    "    track = item[\"track\"]\n",
    "    playlist_info[\"0\"].append({\n",
    "        \"track_name\": track[\"name\"],\n",
    "        \"pos\": idx,\n",
    "        \"album_name\": track[\"album\"][\"name\"],\n",
    "        \"artist_name\": track[\"artists\"][0][\"name\"],  # First artist only\n",
    "        \"duration_ms\": track[\"duration_ms\"]\n",
    "    })\n",
    "\n",
    "# Save the cleaned playlist info\n",
    "with open(\"cleaned_playlist.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(playlist_info, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7e202-71d2-4d7a-bba6-bcc1ea5f7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get my playlist from YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "862880ff-3c15-475c-be0f-e90d79173c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=LL\n",
      "[youtube:tab] LL: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube:tab] The provided YouTube account cookies are no longer valid. They have likely been rotated in the browser as a security measure. For tips on how to effectively export YouTube cookies, refer to  https://github.com/yt-dlp/yt-dlp/wiki/Extractors#exporting-youtube-cookies .\n",
      "WARNING: [youtube:tab] YouTube said: The playlist does not exist.\n",
      "ERROR: [youtube:tab] LL: YouTube said: The playlist does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed to fetch playlist: ERROR: [youtube:tab] LL: YouTube said: The playlist does not exist.\n",
      "⚠️ Skipping video at index 103: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 118: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 166: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 199: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 318: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 435: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 437: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 486: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 567: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 610: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 637: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 685: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 692: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 730: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "⚠️ Skipping video at index 736: unsupported operand type(s) for *: 'NoneType' and 'int'\n",
      "\n",
      "✅ Saved liked_videos.json with 729 tracks.\n"
     ]
    }
   ],
   "source": [
    "from yt_dlp import YoutubeDL\n",
    "import json\n",
    "\n",
    "ydl_opts = {\n",
    "    'cookiefile': 'cookies.txt',\n",
    "    'quiet': False,\n",
    "    'skip_download': True,\n",
    "    'extract_flat': False,\n",
    "}\n",
    "\n",
    "with YoutubeDL(ydl_opts) as ydl:\n",
    "    url = \"https://www.youtube.com/playlist?list=LL\"\n",
    "    try:\n",
    "        info = ydl.extract_info(url, download=False)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch playlist: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "    playlist_data = {\n",
    "        \"name\": info.get(\"title\", \"Liked Videos\"),\n",
    "        \"pid\": info.get(\"id\", \"LL\"),\n",
    "        \"num_tracks\": 0,\n",
    "        \"num_albums\": 0,\n",
    "        \"num_artists\": 0,\n",
    "        \"num_followers\": 0,\n",
    "        \"collaborative\": \"false\",\n",
    "        \"0\": []\n",
    "    }\n",
    "\n",
    "    seen_artists = set()\n",
    "    successful_tracks = 0\n",
    "\n",
    "    for i, entry in enumerate(info.get(\"entries\", [])):\n",
    "        try:\n",
    "            if not entry:\n",
    "                continue\n",
    "\n",
    "            track_name = entry.get(\"title\", \"Unknown Title\")\n",
    "            artist_name = entry.get(\"uploader\", \"Unknown Artist\")\n",
    "            duration = entry.get(\"duration\", 0)  # in seconds\n",
    "\n",
    "            seen_artists.add(artist_name)\n",
    "\n",
    "            track_info = {\n",
    "                \"track_name\": track_name,\n",
    "                \"pos\": successful_tracks,\n",
    "                \"album_name\": \"YouTube\",\n",
    "                \"artist_name\": artist_name,\n",
    "                \"duration_ms\": duration * 1000\n",
    "            }\n",
    "\n",
    "            playlist_data[\"0\"].append(track_info)\n",
    "            successful_tracks += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping video at index {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Finalize counts\n",
    "    playlist_data[\"num_tracks\"] = successful_tracks\n",
    "    playlist_data[\"num_artists\"] = len(seen_artists)\n",
    "\n",
    "    # Save to JSON\n",
    "    try:\n",
    "        with open(\"liked_videos.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(playlist_data, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\n✅ Saved liked_videos.json with {successful_tracks} tracks.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to save JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wHzfuC9r5CCD",
   "metadata": {
    "id": "wHzfuC9r5CCD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>pos</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_pid</th>\n",
       "      <th>playlist_num_tracks</th>\n",
       "      <th>playlist_num_albums</th>\n",
       "      <th>playlist_num_artists</th>\n",
       "      <th>playlist_num_followers</th>\n",
       "      <th>playlist_collaborative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How I Feel</td>\n",
       "      <td>0</td>\n",
       "      <td>How I Feel</td>\n",
       "      <td>Flo Rida</td>\n",
       "      <td>169557</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lo Que No Sabes Tú</td>\n",
       "      <td>1</td>\n",
       "      <td>Mi Niña Bonita - Reloaded</td>\n",
       "      <td>Chino &amp; Nacho</td>\n",
       "      <td>232120</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chucuchá</td>\n",
       "      <td>2</td>\n",
       "      <td>El Sonido</td>\n",
       "      <td>Ilegales</td>\n",
       "      <td>206959</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mueva la colita</td>\n",
       "      <td>3</td>\n",
       "      <td>Top Caribe</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>242373</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Be My Baby</td>\n",
       "      <td>4</td>\n",
       "      <td>Lloviendo Estrellas</td>\n",
       "      <td>Leslie Grace</td>\n",
       "      <td>218253</td>\n",
       "      <td>2014</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           track_name  pos                 album_name      artist_name  \\\n",
       "0          How I Feel    0                 How I Feel         Flo Rida   \n",
       "1  Lo Que No Sabes Tú    1  Mi Niña Bonita - Reloaded    Chino & Nacho   \n",
       "2            Chucuchá    2                  El Sonido         Ilegales   \n",
       "3     Mueva la colita    3                 Top Caribe  Various Artists   \n",
       "4          Be My Baby    4        Lloviendo Estrellas     Leslie Grace   \n",
       "\n",
       "   duration_ms playlist_name playlist_pid  playlist_num_tracks  \\\n",
       "0       169557          2014            8                   21   \n",
       "1       232120          2014            8                   21   \n",
       "2       206959          2014            8                   21   \n",
       "3       242373          2014            8                   21   \n",
       "4       218253          2014            8                   21   \n",
       "\n",
       "   playlist_num_albums  playlist_num_artists  playlist_num_followers  \\\n",
       "0                   21                    19                       1   \n",
       "1                   21                    19                       1   \n",
       "2                   21                    19                       1   \n",
       "3                   21                    19                       1   \n",
       "4                   21                    19                       1   \n",
       "\n",
       "  playlist_collaborative  \n",
       "0                  false  \n",
       "1                  false  \n",
       "2                  false  \n",
       "3                  false  \n",
       "4                  false  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the playlist\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON from file\n",
    "#working_dir = 'C:/Users/carja/Documents/Capstone/'\n",
    "working_dir = '/mnt/c/Users/carja/Documents/Capstone/'\n",
    "with open(working_dir + 'playlist_data3.json', encoding='utf-8') as f:\n",
    "    playlists  = json.load(f)\n",
    "\n",
    "# Flattened track list\n",
    "track_rows = []\n",
    "\n",
    "for playlist in playlists:\n",
    "    # Extract playlist metadata (everything except the track list)\n",
    "    playlist_metadata = {k: v for k, v in playlist.items() if k != '0'}\n",
    "    \n",
    "    # Extract the track list (the key \"0\" holds the tracks)\n",
    "    tracks = playlist.get(\"0\", [])\n",
    "    \n",
    "    for track in tracks:\n",
    "        # Combine track data with playlist metadata\n",
    "        combined = {**track, **playlist_metadata}\n",
    "        track_rows.append(combined)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(track_rows)\n",
    "\n",
    "# Optional: Rename playlist fields to make it clear\n",
    "playlist_fields = ['name', 'pid', 'num_tracks', 'num_albums', 'num_artists', 'num_followers', 'collaborative']\n",
    "df.rename(columns={field: f'playlist_{field}' for field in playlist_fields}, inplace=True)\n",
    "\n",
    "# first remove duplicate tracks to avoid downloading twice\n",
    "df = df.drop_duplicates(subset=['artist_name', 'track_name'])\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea12ee94-3bfd-4009-97b1-e831f0a9d38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>pos</th>\n",
       "      <th>album_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_pid</th>\n",
       "      <th>playlist_num_tracks</th>\n",
       "      <th>playlist_num_albums</th>\n",
       "      <th>playlist_num_artists</th>\n",
       "      <th>playlist_num_followers</th>\n",
       "      <th>playlist_collaborative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>The Green Man - Ragtime</td>\n",
       "      <td>717</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>asx</td>\n",
       "      <td>376000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1539</th>\n",
       "      <td>KIOKO et NISSUI YAKI ONIGIRI 6</td>\n",
       "      <td>720</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>Kioko épicerie japonaise</td>\n",
       "      <td>166000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>\"Weird Al\" Yankovic - Fat (Official Video)</td>\n",
       "      <td>723</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>alyankovic</td>\n",
       "      <td>297000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>Equestria Girls - Rainbow Rocks - 'My Past is ...</td>\n",
       "      <td>726</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>My Little Pony - Official Channel</td>\n",
       "      <td>182000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>Heartcatch Pretty Cure 3rd OP</td>\n",
       "      <td>727</td>\n",
       "      <td>YouTube</td>\n",
       "      <td>mintjn666</td>\n",
       "      <td>86000</td>\n",
       "      <td>Liked videos</td>\n",
       "      <td>LL</td>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             track_name  pos album_name  \\\n",
       "1538                            The Green Man - Ragtime  717    YouTube   \n",
       "1539                     KIOKO et NISSUI YAKI ONIGIRI 6  720    YouTube   \n",
       "1540         \"Weird Al\" Yankovic - Fat (Official Video)  723    YouTube   \n",
       "1541  Equestria Girls - Rainbow Rocks - 'My Past is ...  726    YouTube   \n",
       "1542                      Heartcatch Pretty Cure 3rd OP  727    YouTube   \n",
       "\n",
       "                            artist_name  duration_ms playlist_name  \\\n",
       "1538                                asx       376000  Liked videos   \n",
       "1539           Kioko épicerie japonaise       166000  Liked videos   \n",
       "1540                         alyankovic       297000  Liked videos   \n",
       "1541  My Little Pony - Official Channel       182000  Liked videos   \n",
       "1542                          mintjn666        86000  Liked videos   \n",
       "\n",
       "     playlist_pid  playlist_num_tracks  playlist_num_albums  \\\n",
       "1538           LL                  729                    0   \n",
       "1539           LL                  729                    0   \n",
       "1540           LL                  729                    0   \n",
       "1541           LL                  729                    0   \n",
       "1542           LL                  729                    0   \n",
       "\n",
       "      playlist_num_artists  playlist_num_followers playlist_collaborative  \n",
       "1538                   530                       0                  false  \n",
       "1539                   530                       0                  false  \n",
       "1540                   530                       0                  false  \n",
       "1541                   530                       0                  false  \n",
       "1542                   530                       0                  false  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d584d99-ba09-492c-a8be-d755eaba5a50",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f8784e-0170-40c2-b7d3-e5b486452e38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "fbea0d6e",
    "outputId": "731f7641-13dd-4484-a8ea-106558254bc5",
    "papermill": {
     "duration": 0.13467,
     "end_time": "2021-10-26T11:23:10.700195",
     "exception": false,
     "start_time": "2021-10-26T11:23:10.565525",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "source": [
    "### How many unique albums/tracks/artists are there on playlists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6891116-3556-4394-bcdb-9841fe8a99f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique albums: 1146\n",
      "Unique tracks: 1480\n",
      "Unique artists: 929\n"
     ]
    }
   ],
   "source": [
    "# Unique albums\n",
    "count = df[['artist_name', 'album_name']].drop_duplicates().shape[0]\n",
    "print(\"Unique albums:\", count)\n",
    "\n",
    "# Unique tracks\n",
    "count = df[['artist_name', 'track_name']].drop_duplicates().shape[0]\n",
    "print(\"Unique tracks:\", count)\n",
    "\n",
    "# Unique artists\n",
    "count = df[['artist_name']].drop_duplicates().shape[0]\n",
    "print(\"Unique artists:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572524cf-9d88-4d32-9493-6eb805bc9911",
   "metadata": {},
   "source": [
    "### How many times is the next track from the same album/artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0666c3-b969-441a-8e9e-81d4a5aab017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consecutive tracks by the same album: 786\n",
      "Consecutive tracks by the same artist: 204\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_sequential_matches(df, group_by='playlist_pid', order_by='pos', compare_field='artist_name'):\n",
    "    \"\"\"\n",
    "    Count the number of times two consecutive tracks within the same playlist\n",
    "    share the same value for a specified metadata field (e.g., artist, album).\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas.DataFrame with at least the playlist ID, track position, and metadata field.\n",
    "    - group_by: column to group by (usually playlist ID).\n",
    "    - order_by: column indicating order of tracks within group (usually track position).\n",
    "    - compare_field: metadata field to compare between consecutive tracks.\n",
    "\n",
    "    Returns:\n",
    "    - count: int, number of sequential matches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure correct ordering\n",
    "    df_sorted = df.sort_values(by=[group_by, order_by]).copy()\n",
    "\n",
    "    # Shift the compare_field to get previous track's value\n",
    "    df_sorted['prev_value'] = df_sorted.groupby(group_by)[compare_field].shift()\n",
    "\n",
    "    # Check for equality between current and previous track's metadata\n",
    "    df_sorted['sequential_match'] = df_sorted[compare_field] == df_sorted['prev_value']\n",
    "\n",
    "    # Count number of True values\n",
    "    count = df_sorted['sequential_match'].sum()\n",
    "\n",
    "    return count\n",
    "\n",
    "count = count_sequential_matches(df, compare_field='album_name')\n",
    "print(\"Consecutive tracks by the same album:\", count)\n",
    "\n",
    "count = count_sequential_matches(df)\n",
    "print(\"Consecutive tracks by the same artist:\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09555f7-67bf-4b9a-99d5-04942ee86fac",
   "metadata": {},
   "source": [
    "### Who are the top artists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ef272f-c6a6-4f68-aec9-e8f2f3265016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 artists: artist_name\n",
      "Eve                32\n",
      "A.R. Rahman        26\n",
      "RHINO              19\n",
      "Lata Mangeshkar    19\n",
      "natori             16\n",
      "TopPop             15\n",
      "Ed Sheeran         14\n",
      "Arijit Singh       14\n",
      "Ado                13\n",
      "Pritam             13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def get_top_artists(df, artist_col='artist_name', top_n=10):\n",
    "    \"\"\"\n",
    "    Returns the top N artists based on track frequency in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing tracks.\n",
    "    - artist_col: column name containing artist names.\n",
    "    - top_n: number of top artists to return.\n",
    "\n",
    "    Returns:\n",
    "    - pandas Series with artist names as index and counts as values.\n",
    "    \"\"\"\n",
    "    return df[artist_col].value_counts().head(top_n)\n",
    "\n",
    "top10Artists = get_top_artists(df)\n",
    "print(\"Top 10 artists:\", top10Artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e65a81-2926-487c-bf46-84cd10a65e63",
   "metadata": {},
   "source": [
    "### How many different albums are there for each artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb73684-0dc2-4027-b5a3-319bf2aabfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 artists by number of albums.\n",
      "\n",
      "          artist_name  unique_album_count\n",
      "234              Eve                  17\n",
      "10       A.R. Rahman                  14\n",
      "419  Lata Mangeshkar                  11\n",
      "25               Ado                  11\n",
      "896           natori                   9\n",
      "420             Lavt                   8\n",
      "55      Arijit Singh                   7\n",
      "324     Jack Johnson                   7\n",
      "735      The Beatles                   7\n",
      "489    Mohammed Rafi                   7\n"
     ]
    }
   ],
   "source": [
    "album_counts = (\n",
    "    df.groupby('artist_name')['album_name']\n",
    "      .nunique()       # count unique albums per artist\n",
    "      .reset_index()   # convert Series back to DataFrame\n",
    "      .rename(columns={'album_name': 'unique_album_count'})\n",
    "      .sort_values(by='unique_album_count', ascending=False)\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "print(\"Top 10 artists by number of albums.\\n\\n\", album_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e120f3f-9a63-479d-a9d9-5c46b92da1f4",
   "metadata": {},
   "source": [
    "# Audio Download\n",
    "### https://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#usage-and-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3cc5e3aa-d501-4236-ada4-d8fd223a12e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yt-dlp in c:\\users\\carja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2025.5.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'yt-dlp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3280a90-9fda-4c2d-99ca-c381c75cb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Remove characters not allowed in filenames (Windows, macOS, Linux)\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', '', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a0560b9-4e4f-49ce-9dfe-8589ecb2c4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] -6VYh3fVXlc: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 9zgtT0eCHd4: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] jGflUbPQfW8: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] v4KCuphhFYw: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] CMj-RA8xVIY: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] bzSTpdcs-EI: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] euCqAq6BRa4: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 5fcTCMWx2-s: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] JFF_Mss_uLc: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] JFF_Mss_uLc: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] SfCsb4Ck75w: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] HbHpNpIGI7Q: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] KEI4qSrkPAs: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] -Iq9usG3mBM: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] -Iq9usG3mBM: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] 0Z_YqhYHhpg: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] JhoK7chbpZ0: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] JhoK7chbpZ0: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] nqxVMLVe62U: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] DfKe8K1A3JI: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] _vSwyFLdrFs: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] AdDnqSFYXFs: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] RhxF9Qg5mOU: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] xvqeSJlgaNk: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] -XYBj0J99i8: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] QlJ7jPDJhyU: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n",
      "WARNING: [youtube] QlJ7jPDJhyU: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] DfwsXn5n8HU: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] zg21Rkew874: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] xnKOVPXhlnE: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] qZTwjljm5qc: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] i6iBAuwBODA: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] pbG5iSOe4Y0: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] UFJ0cQ_2-JQ: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] RZUq6N7Gx1c: Some tv client https formats have been skipped as they are DRM protected. The current session may have an experiment that applies DRM to all videos on the tv client. See  https://github.com/yt-dlp/yt-dlp/issues/12563  for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0.  Downloaded 1480. Total 1543                                  \n"
     ]
    }
   ],
   "source": [
    "# Loop over your DataFrame rows and Download the music\n",
    "import os\n",
    "\n",
    "def download_track(search_query, output_template):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'quiet': True,\n",
    "        'noplaylist': True,\n",
    "        'outtmpl': output_template,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([f\"ytsearch1:{search_query}\"])\n",
    "        #print(f\"Downloaded: {search_query}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download '{search_query}': {e}\")   \n",
    "\n",
    "# Make sure downloads folder exists\n",
    "output_dir = working_dir + 'downloads'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "download_count = 0\n",
    "skip_count, download_count = 0, 0\n",
    "for ii, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    safe_name = sanitize_filename(f\"{artist} - {track}\")\n",
    "    output_template = output_dir + '/' + safe_name # os.path.join(output_dir, safe_name)\n",
    "\n",
    "     # ✅ Skip if file already exists\n",
    "    if os.path.exists(output_template):\n",
    "        skip_count += 1\n",
    "        print(f\"Skipping (already exists): {output_template}\")\n",
    "        continue\n",
    "    \n",
    "    download_track(safe_name, output_template)\n",
    "    download_count += 1\n",
    "\n",
    "print(f\"Skipped {skip_count}.  Downloaded {download_count}. Total {ii + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af89d5cc-bda3-4831-a2f6-fe77bf567c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ii' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     audio \u001b[38;5;241m=\u001b[39m audio\u001b[38;5;241m.\u001b[39mset_channels(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mset_frame_rate(\u001b[38;5;241m44100\u001b[39m)\n\u001b[1;32m     28\u001b[0m     audio\u001b[38;5;241m.\u001b[39mexport(wav_file, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipped \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mskip_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Converted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwav_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Total \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mii\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ii' is not defined"
     ]
    }
   ],
   "source": [
    "## Convert mp3 to wavfrom\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Make sure downloads folder exists\n",
    "wav_dir = working_dir + 'wavs'\n",
    "os.makedirs(wav_dir, exist_ok=True)\n",
    "mp3_dir = working_dir + 'downloads'\n",
    "\n",
    "# Loop over your DataFrame rows\n",
    "skip_count, wav_count = 0, 0\n",
    "for idx, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    mp3_name = sanitize_filename(f\"{artist} - {track}.mp3\")\n",
    "    mp3_file = mp3_dir + '/' + mp3_name #os.path.join(output_dir, mp3_name)\n",
    "    wav_name = sanitize_filename(f\"{artist} - {track}.wav\")\n",
    "    wav_file = wav_dir + '/' + wav_name #os.path.join(wav_dir, wav_name)\n",
    "\n",
    "     # ✅ Skip if file doesn't exists\n",
    "    if not os.path.exists(mp3_file) or os.path.exists(wav_file):\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    wav_count += 1\n",
    "    \n",
    "    audio = AudioSegment.from_mp3(mp3_file)\n",
    "    audio = audio.set_channels(1).set_frame_rate(44100)\n",
    "    audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "print(f\"Skipped {skip_count}. Converted {wav_count}. Total {ii + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886493b-16df-452e-8e96-5260af731091",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply Signal Processing\n",
    "### key signature, tempo, chroma, zero crossing rate, MFCC (Mel-frequency cepstral coefficients), spectral bandwidth, RMSE (Root Mean Square Error), etc\n",
    "### I don't want to use a mood or genre classifier because it's a solved problem.\n",
    "### I'm instead going to attempt to extract this metadata from the raw audio\n",
    "### Then I'll calculate sonme distance score using all metadata and use it to match songs for recommendation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0484f6b4-145a-45fa-bfc6-f048f7acb814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (0.61.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/carjam/miniconda3/envs/rapids-24/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "Installing collected packages: soxr, audioread, soundfile, pooch, librosa\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [librosa]\n",
      "\u001b[1A\u001b[2KSuccessfully installed audioread-3.0.1 librosa-0.11.0 pooch-1.8.2 soundfile-0.13.1 soxr-0.5.0.post1\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install librosa\n",
    "#!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38234f1e-da5e-436d-a14b-d21b9ce916b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m track \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m safe_name \u001b[38;5;241m=\u001b[39m sanitize_filename(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m song_file \u001b[38;5;241m=\u001b[39m \u001b[43moutput_dir\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m safe_name \u001b[38;5;66;03m#os.path.join(output_dir, safe_name)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#print(\"\\nAnalyzing \", safe_name)\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m  \u001b[38;5;66;03m# ✅ Skip if file doesn't exists\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(song_file):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m#print(\"Skipping \", song_file)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_dir' is not defined"
     ]
    }
   ],
   "source": [
    "### librosa: https://librosa.org/doc/latest/index.html\n",
    "### (McFee, Brian, Colin Raffel, Dawen Liang, Daniel PW Ellis, Matt McVicar, Eric Battenberg, and Oriol Nieto.\n",
    "### “librosa: Audio and music signal analysis in python.” In Proceedings of the 14th python in science conference, pp. 18-25. 2015.)\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\"\"\" Degree of Harmony\n",
    "    1.0–1.5 → monophonic (no harmony, single note per time).\n",
    "    2.0–3.0 → likely vocal harmonies or chords (e.g., duets, backing vocals).\n",
    "    3.0 → rich harmonic content (dense vocals, synths, or polyphonic instruments).\n",
    "\"\"\"\n",
    "def detectDegreeOfHarmony(chroma):\n",
    "    # Define a threshold as a fraction of the maximum chroma energy\n",
    "    threshold_ratio = 0.5\n",
    "    counts_per_frame = []\n",
    "    \n",
    "    for frame in chroma.T:  # iterate over columns (time frames)\n",
    "        threshold = threshold_ratio * np.max(frame)\n",
    "        strong_pitches = np.sum(frame >= threshold)\n",
    "        counts_per_frame.append(strong_pitches)\n",
    "    \n",
    "    # Convert to numpy array for easy stats\n",
    "    counts_per_frame = np.array(counts_per_frame)\n",
    "    \n",
    "    average_polyphony = np.mean(counts_per_frame)\n",
    "    return average_polyphony\n",
    "    \n",
    "\n",
    "# Krumhansl-Schmuckler key profiles\n",
    "major_profile = [6.35, 2.23, 3.48, 2.33, 4.38, 4.09,\n",
    "                 2.52, 5.19, 2.39, 3.66, 2.29, 2.88]\n",
    "minor_profile = [6.33, 2.68, 3.52, 5.38, 2.60, 3.53,\n",
    "                 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]\n",
    "\n",
    "# Rotate profiles to each of the 12 keys\n",
    "profiles = []\n",
    "key_names = []\n",
    "\n",
    "# Major keys\n",
    "for i in range(12):\n",
    "    profiles.append(np.roll(major_profile, i))\n",
    "    key_names.append(librosa.midi_to_note(60 + i, octave=False) + ' major')\n",
    "\n",
    "# Minor keys\n",
    "for i in range(12):\n",
    "    profiles.append(np.roll(minor_profile, i))\n",
    "    key_names.append(librosa.midi_to_note(60 + i, octave=False) + ' minor')\n",
    "\n",
    "\n",
    "# Loop over your DataFrame rows\n",
    "skip_count, analyze_count = 0, 0\n",
    "for ii, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    safe_name = sanitize_filename(f\"{artist} - {track}.mp3\")\n",
    "    song_file = output_dir + '/' + safe_name #os.path.join(output_dir, safe_name)\n",
    "    #print(\"\\nAnalyzing \", safe_name)\n",
    "\n",
    "     # ✅ Skip if file doesn't exists\n",
    "    if not os.path.exists(song_file):\n",
    "        #print(\"Skipping \", song_file)\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    analyze_count += 1\n",
    "\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(song_file)\n",
    "    \n",
    "    # Get the chroma features (energy per pitch class)\n",
    "    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "    # Degree of Harmony\n",
    "    df.at[ii, 'harmony_degree'] = detectDegreeOfHarmony(chroma)\n",
    "    #print(f\"Average number of strong pitch classes per frame: {df.at[ii, 'harmony_degree']:.2f}\")\n",
    "\n",
    "    # Average chroma over time to get a pitch class profile\n",
    "    chroma_mean = np.mean(chroma, axis=1)\n",
    "    # Correlate chroma vector with all key profiles\n",
    "    correlations = [np.corrcoef(chroma_mean, profile)[0, 1] for profile in profiles]\n",
    "    # Get the key with the highest correlation\n",
    "    best_index = np.argmax(correlations)\n",
    "    estimated_key = key_names[best_index]\n",
    "    df.at[ii, 'estimated_key'] = estimated_key\n",
    "    #print(f\"Estimated key: {estimated_key}\")\n",
    "    \n",
    "    \n",
    "    # Detect tempo and beats\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    # Convert beat frames to time (seconds)\n",
    "    beat_times = librosa.frames_to_time(beat_frames, sr=sr)\n",
    "    tempo_val = float(np.squeeze(tempo))\n",
    "    df.at[ii, 'tempo'] = tempo_val\n",
    "    #print(f\"Estimated tempo: {tempo_val:.2f} BPM\")\n",
    "    \n",
    "    \n",
    "    # MFCCs (timbre)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    df.at[ii, 'mfcc_shape'] = str(mfccs.shape) # convert Tuple to string to allow assignment\n",
    "    #print(\"MFCC shape:\", mfccs.shape)\n",
    "    \n",
    "    # Spectral features (reverb, distortion, timbre)\n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_contrast_mean, spectral_contrast_var = np.mean(spectral_contrast), np.std(spectral_contrast)\n",
    "    df.at[ii, 'spectral_contrast_mean'] = spectral_contrast_mean\n",
    "    df.at[ii, 'spectral_contrast_var'] = spectral_contrast_var\n",
    "    #print(f\"Average, Var spectral contrast: {spectral_contrast_mean:.2f}, {spectral_contrast_var:.2f} Hz\")\n",
    "    \n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_centroid_mean, spectral_centroid_var = np.mean(spectral_centroid), np.std(spectral_centroid)\n",
    "    df.at[ii, 'spectral_centroid_mean'] = spectral_centroid_mean\n",
    "    df.at[ii, 'spectral_centroid_var'] = spectral_centroid_var\n",
    "    #print(f\"Average, Var spectral centroid: {spectral_centroid_mean:.2f}, {spectral_centroid_var:.2f} Hz\")\n",
    "    \n",
    "    spectral_flatness = librosa.feature.spectral_flatness(y=y)\n",
    "    spectral_flatness_mean, spectral_flatness_var = np.mean(spectral_flatness), np.std(spectral_flatness)\n",
    "    df.at[ii, 'spectral_flatness_mean'] = spectral_flatness_mean\n",
    "    df.at[ii, 'spectral_flatness_var'] = spectral_flatness_var\n",
    "    #print(f\"Average, Var spectral flatness: {spectral_flatness_mean:.2f}, {spectral_flatness_var:.2f} Hz\")\n",
    "\n",
    "print(f\"Skipped {skip_count}.  Analyzed {analyze_count}. Total {ii + 1}\")\n",
    "\n",
    "## Save progress\n",
    "df.to_csv(working_dir + 'initialAnalysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d96e09-605b-475d-a0e2-26eda9a9839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load saved progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93de6416-1d47-4e99-a7e6-a947054557d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#df = pd.read_csv(working_dir + 'initialAnalysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4e65c-726b-4c91-aa92-732653de165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify Chord Progress\n",
    "## Get Tonic from Key\n",
    "## Mod based on Tonic\n",
    "## Save \"factorized\" progression pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "329f17d4-ef4a-43d8-9dd3-de50111f44f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 730. Converted 1. Total 731\n"
     ]
    }
   ],
   "source": [
    "## Get Chord Progression & save to csv\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Make sure chords folder exists\n",
    "chords_dir = working_dir + 'chords'\n",
    "os.makedirs(chords_dir, exist_ok=True)\n",
    "\n",
    "# Loop over your DataFrame rows\n",
    "skip_count, chord_count = 0, 0\n",
    "for idx, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    wav_name = sanitize_filename(f\"{artist} - {track}.wav\")\n",
    "    wav_file = wav_dir + '/' + wav_name #os.path.join(wav_dir, wav_name)\n",
    "    chords_name = sanitize_filename(f\"{artist} - {track}.csv\")\n",
    "    chords_file = chords_dir + '/' + chords_name # os.path.join(chords_dir, chords_name)\n",
    "    \n",
    "     # ✅ Skip if file doesn't exists\n",
    "    if not os.path.exists(wav_file) or (os.path.exists(chords_file) and os.path.getsize(chords_file) > 0):\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    chord_count += 1\n",
    "    \n",
    "    command = [\n",
    "        'C:/sonic-annotator-1.6-win64/sonic-annotator.exe',\n",
    "        '-d', 'vamp:nnls-chroma:chordino',\n",
    "        '-w', 'csv',\n",
    "        '--csv-stdout',\n",
    "        wav_file\n",
    "    ]\n",
    "    \n",
    "    # Run and capture output\n",
    "    with open(chords_file, \"w\") as f:\n",
    "        subprocess.run(command, stdout=f, shell=True)\n",
    "        #result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n",
    "        #print(\"STDOUT:\", result.stdout.decode())\n",
    "        #print(\"STDERR:\", result.stderr.decode())\n",
    "\n",
    "print(f\"Skipped {skip_count}. Converted {chord_count}. Total {ii + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0e5cf54-f049-4127-aca3-45bfc36ed544",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the chord output to factorize to an estimate per track chord progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8208e66a-2bc9-44bb-a354-afedfa8555d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting music21==6.1.0\n",
      "  Downloading music21-6.1.0.tar.gz (18.3 MB)\n",
      "     ---------------------------------------- 0.0/18.3 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 2.9/18.3 MB 16.3 MB/s eta 0:00:01\n",
      "     ----------- ---------------------------- 5.2/18.3 MB 15.6 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 8.4/18.3 MB 15.1 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 11.5/18.3 MB 14.8 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 12.6/18.3 MB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 14.4/18.3 MB 11.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 16.8/18.3 MB 12.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  17.8/18.3 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------- 18.3/18.3 MB 10.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting chardet (from music21==6.1.0)\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\carja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from music21==6.1.0) (1.5.0)\n",
      "Collecting more-itertools (from music21==6.1.0)\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: webcolors in c:\\users\\carja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from music21==6.1.0) (24.11.1)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Building wheels for collected packages: music21\n",
      "  Building wheel for music21 (pyproject.toml): started\n",
      "  Building wheel for music21 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for music21: filename=music21-6.1.0-py3-none-any.whl size=20946300 sha256=36345cab8c26e271e9bdb4f2e244f2f91a63a46099d0dd3557ddd2b5b542d8bd\n",
      "  Stored in directory: c:\\users\\carja\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local\\pip\\cache\\wheels\\b2\\0a\\be\\92c6e919b2d564ee577f1e5ad44adfc91ee332f041e222fb6f\n",
      "Successfully built music21\n",
      "Installing collected packages: more-itertools, chardet, music21\n",
      "\n",
      "   ------------- -------------------------- 1/3 [chardet]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   ---------------------------------------- 3/3 [music21]\n",
      "\n",
      "Successfully installed chardet-5.2.0 more-itertools-10.7.0 music21-6.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'C:\\Users\\carja\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install music21==6.1.0 --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "457416c2-d7ba-4375-8256-f44f97a12bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           track_name  pos                 album_name      artist_name  \\\n",
      "0          How I Feel    0                 How I Feel         Flo Rida   \n",
      "1  Lo Que No Sabes Tú    1  Mi Niña Bonita - Reloaded    Chino & Nacho   \n",
      "2            Chucuchá    2                  El Sonido         Ilegales   \n",
      "3     Mueva la colita    3                 Top Caribe  Various Artists   \n",
      "4          Be My Baby    4        Lloviendo Estrellas     Leslie Grace   \n",
      "\n",
      "   duration_ms playlist_name  playlist_pid  playlist_num_tracks  \\\n",
      "0       169557          2014             8                   21   \n",
      "1       232120          2014             8                   21   \n",
      "2       206959          2014             8                   21   \n",
      "3       242373          2014             8                   21   \n",
      "4       218253          2014             8                   21   \n",
      "\n",
      "   playlist_num_albums  playlist_num_artists  playlist_num_followers  \\\n",
      "0                   21                    19                       1   \n",
      "1                   21                    19                       1   \n",
      "2                   21                    19                       1   \n",
      "3                   21                    19                       1   \n",
      "4                   21                    19                       1   \n",
      "\n",
      "  playlist_collaborative  harmony_degree estimated_key       tempo  \\\n",
      "0                  false        6.252057       F major  129.199219   \n",
      "1                  false        6.759421       A major  161.499023   \n",
      "2                  false        5.552326       A minor  143.554688   \n",
      "3                  false        8.606572       A minor  143.554688   \n",
      "4                  false        5.160153       E major  135.999178   \n",
      "\n",
      "    mfcc_shape  spectral_contrast_mean  spectral_contrast_var  \\\n",
      "0   (13, 7657)               20.982608              10.933041   \n",
      "1  (13, 10429)               21.978933              10.837218   \n",
      "2   (13, 9565)               21.571914              11.482156   \n",
      "3  (13, 10439)               21.831782              11.340198   \n",
      "4   (13, 9647)               23.562929              10.570873   \n",
      "\n",
      "   spectral_centroid_mean  spectral_centroid_var  spectral_flatness_mean  \\\n",
      "0             2618.916887             884.297638                0.083479   \n",
      "1             2669.439985            1072.773202                0.035265   \n",
      "2             2611.644154             805.895231                0.047437   \n",
      "3             3234.542515             923.744791                0.065276   \n",
      "4             2529.698759             879.968375                0.037706   \n",
      "\n",
      "   spectral_flatness_var                       progression1  \\\n",
      "0               0.208154  [v, vi, ii, iio, bVII, vi, ii, I]   \n",
      "1               0.071630                    [i, iv, i, iio]   \n",
      "2               0.125170         [iv, bVII, i, iv, bVII, i]   \n",
      "3               0.099380           [bVI, v, bVI, v, bVI, v]   \n",
      "4               0.125490                    [IV, V, biv, I]   \n",
      "\n",
      "                          progression2 tonic   mode  \n",
      "0  [ii, I, bVII, ii, iio, bVII, ii, I]     F  major  \n",
      "1                      [iv, i, iio, i]     A  major  \n",
      "2                 [i, iv, bVII, i, iv]     A  minor  \n",
      "3     [V, bVII, V, bVII, i, I, iio, I]     A  minor  \n",
      "4       [V, biv, I, vi, IV, V, biv, I]     E  major  \n",
      "Skipped 7. Analyzed 724. Total 731\n"
     ]
    }
   ],
   "source": [
    "from music21 import key as m21key, roman, chord, pitch, harmony\n",
    "from collections import Counter\n",
    "import re\n",
    "from typing import List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "# Simplify chords\n",
    "def clean_chord(ch):\n",
    "    # Only use base chord (before colon) and strip whitespace\n",
    "    return ch.split(\":\")[0].strip()\n",
    "\n",
    "def normalize_chord_symbol(ch_str):\n",
    "    # Split bass note off\n",
    "    base = ch_str.split('/')[0]\n",
    "    \n",
    "    # Replace unicode flats '♭' with 'b'\n",
    "    base = base.replace(\"♭\", \"b\")\n",
    "    # Replace flats 'b' that occur immediately after a note letter with '-'\n",
    "    # e.g. 'Eb7' -> 'E-7'\n",
    "    import re\n",
    "    # Pattern: letter followed by 'b'\n",
    "    base = re.sub(r'([A-Ga-g])b', r'\\1-', base)\n",
    "    \n",
    "    # Replace unicode sharps '♯' with '#'\n",
    "    base = base.replace('♯', '#')\n",
    "    \n",
    "    # Recombine with bass if present\n",
    "    if '/' in ch_str:\n",
    "        bass = ch_str.split('/')[1]\n",
    "        return base + '/' + bass\n",
    "    else:\n",
    "        return base\n",
    "\n",
    "def simplify_to_triad(chord_str: str):\n",
    "    try:\n",
    "        chord_str.closedPosition(forceOctave=4, inPlace=True)\n",
    "        root = chord_str.root()\n",
    "        quality = chord_str.commonName\n",
    "\n",
    "        # Decide triad type based on commonName\n",
    "        if \"major\" in quality.lower():\n",
    "            return harmony.ChordSymbol(f\"{root.name}\")\n",
    "        elif \"minor\" in quality.lower():\n",
    "            return harmony.ChordSymbol(f\"{root.name}m\")\n",
    "        elif \"diminished\" in quality.lower() or \"dim\" in quality.lower():\n",
    "            return harmony.ChordSymbol(f\"{root.name}dim\")\n",
    "        elif \"augmented\" in quality.lower() or \"aug\" in quality.lower():\n",
    "            return harmony.ChordSymbol(f\"{root.name}aug\")\n",
    "        else:\n",
    "            return harmony.ChordSymbol(root.name)  # Default to major if unclear\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to simplify {chord_str}: {e}\")\n",
    "        return None\n",
    "\n",
    "'''\n",
    "    Map chords to Roman numerals \n",
    "    We first simplify the chords to their triads\n",
    "    This makes pattern recognition stronger by de-emphasizing embelishments\n",
    "'''\n",
    "def chord_to_roman(chord_symbol, song_key):\n",
    "        try:\n",
    "            # Try parsing with ChordSymbol (handles complex symbols better)\n",
    "            cs = harmony.ChordSymbol(chord_symbol)\n",
    "            # This sometimes returns no pitches if parsing failed, check:\n",
    "            if not cs.pitches:\n",
    "                raise ValueError(f\"No pitches parsed for chord '{chord_symbol}'\")\n",
    "            triad = simplify_to_triad(cs)\n",
    "            rn = roman.romanNumeralFromChord(triad, song_key)\n",
    "            return rn.figure\n",
    "        except Exception as e:\n",
    "            # As fallback, try parsing just root note and quality manually\n",
    "            try:\n",
    "                # Remove bass note (after slash)\n",
    "                base_chord = chord_symbol.split('/')[0]\n",
    "                cs = harmony.ChordSymbol(base_chord)\n",
    "                triad = simplify_to_triad(cs)\n",
    "                rn = roman.romanNumeralFromChord(triad, song_key)\n",
    "                return rn.figure\n",
    "            except Exception as e2:\n",
    "                print(f\"Failed to convert '{chord_symbol}': {e2}\")\n",
    "                return None\n",
    "\n",
    "'''\n",
    "    Searches the sequence for looped sequences. if none is found returns the most frequent patterns.\n",
    "    weights resolutions that resolve to the key\n",
    "    weights length to prevent \"greedy\" tendency of shorter sequences to dominate repetitions\n",
    "    reduces overlap in sequences by checking equality, subset, and intersection > min_len\n",
    "'''\n",
    "def is_subpattern(smaller, larger):\n",
    "    \"\"\"Check if 'smaller' is a contiguous subpattern of 'larger'.\"\"\"\n",
    "    for i in range(len(larger) - len(smaller) + 1):\n",
    "        if tuple(larger[i:i + len(smaller)]) == smaller:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def cadence_bonus(pattern):\n",
    "    \"\"\"Add score based on how the pattern ends.\"\"\"\n",
    "    if len(pattern) < 2:\n",
    "        return 0\n",
    "\n",
    "    end = pattern[-2:]\n",
    "    last = pattern[-1]\n",
    "\n",
    "    # Strong cadences\n",
    "    if end == ['V', 'I'] or end == ['V7', 'I']:\n",
    "        return 8  # Authentic cadence\n",
    "    if end == ['IV', 'I']:\n",
    "        return 5  # Plagal cadence\n",
    "    if end == ['V', 'vi']:\n",
    "        return 3  # Deceptive cadence\n",
    "    if pattern[-3:] == ['ii', 'V', 'I']:\n",
    "        return 6  # 2-5-1 cadence\n",
    "    if pattern[-3:] == ['I', 'IV', 'V'] or pattern[-4:] == ['I', 'IV', 'V', 'I']:\n",
    "        return 6  # Full cadence\n",
    "    if pattern[-4:] == ['I', 'V', 'vi', 'IV']:\n",
    "        return 4  # Axis progression\n",
    "    if end == ['bVII', 'I']:\n",
    "        return 4  # Modal cadence (Mixolydian)\n",
    "\n",
    "    # Melodic feel resolutions\n",
    "    if last == 'I':\n",
    "        return 2  # Tonic resolution\n",
    "    if last == 'iii':\n",
    "        return 2  # Mediant (3rd) resolution\n",
    "    if last == 'vi':\n",
    "        return 1  # Submediant resolution\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def find_top_two_progression_patterns(progression, min_len, max_len):\n",
    "    n = len(progression)\n",
    "    pattern_counts = defaultdict(int)\n",
    "    pattern_positions = defaultdict(list)\n",
    "\n",
    "    # Step 1: Identify all patterns and their positions\n",
    "    for i in range(n):\n",
    "        for length in range(min_len, max_len + 1):\n",
    "            if i + length <= n:\n",
    "                pattern = tuple(progression[i:i + length])\n",
    "                pattern_counts[pattern] += 1\n",
    "                pattern_positions[pattern].append((i, i + length))  # store as (start, end)\n",
    "\n",
    "    scored_patterns = []\n",
    "\n",
    "    for pattern, positions in pattern_positions.items():\n",
    "        last_chord = pattern[-1]\n",
    "        resolution_bonus = cadence_bonus(pattern)\n",
    "\n",
    "        # Check for strict looping\n",
    "        is_looping = False\n",
    "        if len(positions) > 1:\n",
    "            distances = [j[0] - i[0] for i, j in zip(positions, positions[1:])]\n",
    "            if all(d == len(pattern) for d in distances):\n",
    "                is_looping = True\n",
    "\n",
    "        base_score = len(pattern) + resolution_bonus if is_looping else pattern_counts[pattern] * len(pattern) + resolution_bonus\n",
    "        scored_patterns.append((base_score, pattern, pattern_counts[pattern], positions))\n",
    "\n",
    "    # Sort by score descending\n",
    "    scored_patterns.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    top_matches = []\n",
    "\n",
    "    for score, pattern, count, positions in scored_patterns:\n",
    "        pattern_list = list(pattern)\n",
    "\n",
    "        # Check against previously selected patterns\n",
    "        is_valid = True\n",
    "        for existing in top_matches:\n",
    "            # Subset/duplicate check\n",
    "            if (\n",
    "                pattern == tuple(existing['pattern']) or\n",
    "                is_subpattern(pattern, existing['pattern']) or\n",
    "                is_subpattern(existing['pattern'], pattern)\n",
    "            ):\n",
    "                is_valid = False\n",
    "                break\n",
    "\n",
    "            # Overlap check\n",
    "            for p_start, p_end in positions:\n",
    "                for e_start, e_end in existing['positions']:\n",
    "                    overlap = max(0, min(p_end, e_end) - max(p_start, e_start))\n",
    "                    if overlap > min_len:\n",
    "                        is_valid = False\n",
    "                        break\n",
    "                if not is_valid:\n",
    "                    break\n",
    "\n",
    "        if is_valid:\n",
    "            top_matches.append({\n",
    "                \"pattern\": pattern_list,\n",
    "                \"repetitions\": count,\n",
    "                \"positions\": positions\n",
    "            })\n",
    "\n",
    "        if len(top_matches) == 2:\n",
    "            break\n",
    "\n",
    "    # Remove 'positions' before returning if not needed\n",
    "    for match in top_matches:\n",
    "        del match['positions']\n",
    "\n",
    "    return top_matches\n",
    "\n",
    "\n",
    "# Loop over your DataFrame rows\n",
    "skip_count, progression_count = 0, 0\n",
    "for ii, row in df.iterrows():\n",
    "    artist = row['artist_name']\n",
    "    track = row['track_name']\n",
    "    chords_name = sanitize_filename(f\"{artist} - {track}.csv\")\n",
    "    chords_file = chords_dir + '/' + chords_name # os.path.join(chords_dir, chords_name)\n",
    "    \n",
    "     # ✅ Skip if file doesn't exists\n",
    "    if not os.path.exists(chords_file) or os.path.getsize(chords_file) <= 0:\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    progression_count += 1\n",
    "    \n",
    "    # Step 1: Define key\n",
    "    key_str = row[\"estimated_key\"].replace(\"♯\", \"#\").replace(\"♭\", \"b\")  # Change this to your key\n",
    "    tonic, mode = key_str.split()\n",
    "    df.at[ii, 'tonic'] = tonic\n",
    "    df.at[ii, 'mode'] = mode\n",
    "    song_key = m21key.Key(tonic, mode)\n",
    "\n",
    "    # sanitze chords and translate to sequences within their key\n",
    "    df_chord = pd.read_csv(chords_file, comment=\"#\", header=None)\n",
    "    df_chord.columns = [\"start\", \"duration\", \"chord\"]\n",
    "\n",
    "    # clean chord syntax, simplify to their closest triad\n",
    "    # mod to their key to represent as general numeric progression for key-indifferent comparison\n",
    "    chords_clean = [clean_chord(ch) for ch in df_chord[\"chord\"] if ch != \"N\"]\n",
    "    normal_chords = [normalize_chord_symbol(ch) for ch in chords_clean if ch != \"N\"]\n",
    "    roman_chords = [chord_to_roman(ch, song_key) for ch in normal_chords]\n",
    "    roman_chords = [rc for rc in roman_chords if rc is not None]\n",
    "\n",
    "    # most songs are in 4/4 time so we'll look for sequences divisible by 4\n",
    "    sequences = find_top_two_progression_patterns(roman_chords, 4, 8)\n",
    "    #print(f\"\\n{chords_name}\")\n",
    "    \n",
    "    for jj, seq in enumerate(sequences, 1):\n",
    "        #print(f\"Progressions #{jj}: Pattern = {seq['pattern']}, Repetitions = {seq['repetitions']}\")\n",
    "        df.at[ii, 'progression' + str(jj)] = seq['pattern']\n",
    "\n",
    "print(df.head())\n",
    "print(f\"Skipped {skip_count}. Analyzed {progression_count}. Total {ii + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1d737340-ff4e-433b-ac14-08573774c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save progress\n",
    "df.to_csv(working_dir + 'analyzedTracks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13a18c7-f8a2-43a2-8918-8f25cabe4eff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 55.905606,
   "end_time": "2021-10-26T11:23:57.027692",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-26T11:23:01.122086",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
